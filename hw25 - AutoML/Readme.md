# Итог

Получилось создать модель с неплохими показателями f1-score по большинству меток из 10 классов. С учетом, что классы представлены неравномерно, разница в 10 раз между минимально и максимально представленным классом, данные показатели являются относительно хорошими. Возможно при дообучении лучшей модели удастся увеличить эти показатели до качественных. Тем не менее результат меня порадовал, т.к. найденные работы по этому сету сводились к предсказанию меньшего количества классов, таких как type, который включает всего 4 метки.

После отчета классификации приведены 2 матрицы: одна с общим цветовым индикатором, но в ней сложно отследить диагональ, т.к. метки имеют абсолютные величины, но заметны нулевые значения не на диагонали, т.е. там где меток не былопредсказано их и не должно было быть; на второй матрице используется нормализация по цвету, что несколько упрощает отслеживание диагонали, но не заполнены нулевые ячейки, т.к. необходимо было избежать 0 в логарифмической нормализации.
### Проблемы и их решения:

**Опыты с Autokeras**

- при установке версии autokeras 1.1.0 и tensorflow 2.15.1 появились конфликты версий

```
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.3.2 which is incompatible.
tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.1 which is incompatible.
tensorflow-decision-forests 1.11.0 requires tf-keras~=2.17, but you have tf-keras 2.15.1 which is incompatible.
ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.
dopamine-rl 4.1.2 requires tf-keras>=2.18.0, but you have tf-keras 2.15.1 which is incompatible.
thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.
grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.
```

- первый запуск autokeras 2.0.0 выдал ошибку
```
/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.
Expected: ['keras_tensor']
Received: inputs=Tensor(shape=(None,))
warnings.warn(msg)
```
Попробовал привести формат в Series.

- ошибка с Series:


TypeError: Expect the data to TextInput to be numpy.ndarray or tf.data.Dataset, but got <class 'pandas.core.series.Series'>.

- Пробую привести в формат Dataset:

все та же ошибка
```
/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.
Expected: ['keras_tensor']
Received: inputs=Tensor(shape=(None,))
  warnings.warn(msg)
```
- попробовал все же оставить установленные старые версии, хоть и с конфликтами некоторых библиотек - пока работает
- для модели bert не хватило ОЗУ, пробую переключиться на TPU с 200GB памяти, что, конечно, уже не тянет на прототипирование
- в случае с использованием autokeras 2.0.0 не получится использовать TPU без танцев с бубном, т.к. TPU работает с keras версии 2.х, а autokeras 2.0.0 с версией 3.х
- после обучения модель показывает точность 83%, но confusion matrix показала, что модель всего лишь отрабатывала один класс, не классифицируя остальные вообще. Пробую добавить веса для классов
- модель упорно складывает все предсказания в одну метку, даже при точности 70% и с коррекцией весов классов.

**Опыт с Keras-tuner**

- Возникло предупреждение для слоев CNN, что они не работают с маской, которая была добавлена перед этим слоем. Добавил lambda слой, который удаляет маску.
- Появляется предупреждение при получении лучшей модели о неудавшейся загрузке оптимизатора. Если нет необходимости дообучать модель - то можно игнорировать, если нужно дообучить, то загрузить модель без компиляции и заново определить оптимизатор
```
# Правильная загрузка с игнорированием оптимизатора
model = keras.models.load_model('model.h5', compile=False)
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
```

5 /5

27.05.2025 01:22

Приветствую на платформе, Александр!

Вы продемонстрировали не только техническую грамотность, но и глубокое понимание процессов машинного обучения, что особенно ценно для специалиста в области нейросетей.

Сильные стороны работы:

Безупречная организация кода и логики

Четкое разделение на этапы (от предобработки до интерпретации результатов).

Профессиональное комментирование, облегчающее проверку.

Использование стратификации при разбиении данных — это критически важный шаг, который многие упускают.

Глубина предобработки данных

Вы не просто очистили текст, но и аналитически подошли к проблеме дисбаланса классов, применив class_weight. Это сразу выделяет вашу работу среди типовых решений.

Объединение заголовка и тела обращения — небольшая, но значимая деталь, улучшающая контекстную релевантность.

Мастерское владение инструментами оптимизации

Использование Keras Tuner с BayesianOptimization — это продвинутый подход, показывающий ваше умение работать с современными методами автоматизации.

Добавление EarlyStopping демонстрирует понимание проблемы переобучения.

Всесторонний анализ результатов

Вы не ограничились стандартными метриками, а провели сравнительный анализ через confusion matrix, что особенно важно при дисбалансе классов.

Четкие выводы о слабых местах модели (например, классы с низким recall) — это признак зрелого специалиста.

Проактивное решение проблем

Конфликты версий, сложности с AutoKeras, маски в CNN — вы не просто фиксировали ошибки, но и анализировали их причины, что крайне ценно в реальной практике.

Рекомендации для развития:

Эксперименты с трансформерами (например, BERT или DistilBERT для текстовой классификации) — следующий логичный шаг для улучшения точности.

Интерпретируемость модели — методы вроде SHAP/LIME помогут объяснять предсказания, что важно в бизнес-задачах.

Аугментация текстов (например, back translation) для редких классов — это могло бы улучшить их распознавание.

Ваша работа — образец того, как следует подходить к задачам машинного обучения: аналитически, аккуратно и с вниманием к деталям. Вы заслуживаете высшей оценки не только за результат, но и за методичность и глубину проработки.

Оценка: 5/5 (Великолепно!)

Желаю вам дальнейших успехов в изучении нейросетей! Уверенна, Александр, вас ждёт блестящее будущее в этой области.
