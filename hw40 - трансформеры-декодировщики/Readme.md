# Итог
Не смотря на малый срез датасета из 10000 примеров и всего одну эпоху обучения, модель очень хорошо смогла выделить суть новостей для создания заголовков к ним. При этом Beam-search показал себя наиболее эффективным, жадный поиск для небольшой генерации остается на уровне с Beam, а сэмплинг показал большее отклонение от точных выборов токенов заголовка, что может быть полезно для креативных заголовков, тогда как первые два представляют выжимку из самой новости.


---



Датасет хоть и был использован небольшим срезом, но предобработан с возможностью его использования полноценно, убраны слишком ддлинные и слишком короткие новости, токенизация проведена предварительно и добавлена в датасет для ускорения обучения, а колонка для подачи в модель формировалась через `{text}{tokenizer.eos_token}{title}.{tokenizer.eos_token}` с добавлением токена eos как разделителя между новостью и заголовком.


---



Таким образом модель учится предсказывать последовательность от начала текста до второго токена `</s>` который завершает генерацию. На вход инференса мы передаем модели тело новости до первого токена `</s>` и ожидаем генерацию от модели второй части - заголовка.


---



При подготовке датасета возникла сложность с управлением памятью, так как манипуляции с датасетом в ОЗУ вызывали переполнение. Использовал промежуточные сохранения а так же создание hf_dataset напрямую из файла в конечном варианте, что помогло при передаче в тренер.

Так же ускорению способствовали настройки
```
model.gradient_checkpointing_enable()
model = torch.compile(model)
```
а так же
```
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    fp16=True,
    optim="adafactor",
    dataloader_pin_memory=True,
```
в аргументах тренера:

- батч сайз * накопление градиента дают эффективный размер батча в 32

- включение смешанной точност

- оптимизатор `adafactor` уменьшает потребленме памяти

- `dataloader_pin_memory=True` ускоряет загрузку данных на ГПУ.


5 /5

23.09.2025 01:50

Приветствую на платформе, Александр!

Выполнение задания на 5 баллов — это серьезный вызов, и Вы вновь с ним справились блестяще.

Сразу хочу отметить Ваш осознанный и методичный подход к работе. Вы продемонстрировали отличные навыки инженера машинного обучения, начиная с этапа подготовки данных. Тщательный анализ датасета, фильтрация новостей по длине для оптимизации обучения и предварительная токенизация — все это свидетельствует о глубоком понимании процесса. Выбор формата {текст}{EOS}{заголовок}.{EOS} является концептуально верным и элегантным решением для обучения модели последовательной генерации заголовка после текста.

Особого внимания заслуживает Ваша работа по оптимизации вычислительного процесса. Использование gradient_checkpointing, torch.compile, AdaFactor оптимизатора и настройки эффективного размера батча через gradient_accumulation_steps — это профессиональные техники, которые позволили провести обучение максимально эффективно даже на 10000 примерах. Решение проблемы с памятью через работу с файлами, а не исключительно в оперативной памяти, также говорит о Вашей практической сноровке.

Результаты инференса впечатляют, особенно учитывая скромный объем данных для дообучения. Вы не только успешно обучили модель генерировать заголовки, но и провели сравнительный анализ стратегий декодирования (greedy, beam search, sampling), что является признаком зрелого подхода к исследованию. Ваше наблюдение о том, что beam-search дает наиболее точные результаты, а сэмплинг может быть полезен для креативности, абсолютно верно и ценно.

Ваш итоговый отчет содержит развернутые выводы, которые являются сильной стороной данной работы. Вы четко описали архитектурные решения, возникшие трудности и методы их решения, а также интерпретировали полученные результаты. Это образцовая практика, которая значительно повышает ценность проделанной работы.

На основании вышеизложенного и соблюдения всех условий задания №3, я с уверенностью выставляю Вам высшую оценку:

Оценка: 5/5

Александр, Ваша работа выполнена на высоком профессиональном уровне. Вы продемонстрировали владение всем циклом работы с нейросетью: от предобработки данных до анализа результатов. Структура кода логична, а ключевые шаги снабжены комментариями.  
Продолжайте в том же духе！