{"cells":[{"cell_type":"markdown","metadata":{"id":"Sc1EHoIGKvDD"},"source":["**Навигация по уроку**\n","1. [Галлюцинации в LLM](https://colab.research.google.com/drive/19U6Hv3rpK7kOTCO2-HKYbdx65-Ku3te0)\n","2. [Knowledge Graph. Борьба с галлюцинациями](https://colab.research.google.com/drive/1jUSnsx-QrLK0fLmzjryAq-mPbfTPg4tr)\n","3. [Knowledge Graph в действии](https://colab.research.google.com/drive/1rRQYo0VYvbDG-wfm43bTDHC_u4XErPyW)\n","4. [Домашняя работа](https://colab.research.google.com/drive/1psJR6wk6i7MbtYvOu_pM2M6bsoReE5pD)"]},{"cell_type":"markdown","metadata":{"id":"8gw5ypUWTVlx"},"source":["**В домашней работе вы должны сделать:**\n","1. **На 3 балла**. Собрать интерфейс Gradio для модели из урока. В качестве данных выбрать любую статью или статьи из википедии. Должна быть кнопка распарсить данные и отправить запрос.\n","\n","2. **На 4 балла**. Изучите представленные [Ридеры](https://llamahub.ai/?tab=readers) на Llama Hub. С помощью выбранного Ридера (любой кроме википедии) загрузите данные в графовую базу данных. И выполните первое задание ДЗ с этим Ридером.\n","\n","3. **На 5 баллов**. Выполните первое задание. В качестве модели используйте любую русскоязычную модель от [SberDevice](https://huggingface.co/ai-forever). Изучите порядок загрузки модели (он изменится), как поменяется промпт и настройки модели.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GdYCF_QeCF0f"},"source":["# Модель FRED-T5-1.7B"]},{"cell_type":"markdown","metadata":{"id":"2uwljAQcCK2n"},"source":["Особенностью модели является возможность использования префиксов `'<LM>', '<SC1>',.. '<SC6>'`\n","\n","- **Вариант с `<LM>` (Language Modeling)**\n","```\n","prompt = f\"<LM>Контекст: {graph_db_context}\\nВопрос: {user_question}\\nОтвет:\"\n","```\n","\n","**Особенности:**\n","\n","Режим работы: Активирует \"чистое\" языковое моделирование, где модель генерирует текст максимально естественно, опираясь на контекст.\n","\n","**Преимущества:**\n","\n","Ответы более креативные и развернутые, так как <LM> не накладывает жестких ограничений.\n","\n","Лучше подходит для свободных диалогов или генерации объяснений.\n","\n","**Недостатки:**\n","\n","Может игнорировать контекст, если он противоречит предобученным знаниям модели.\n","\n","Риск галлюцинаций (вымышленных фактов).\n","\n","**Пример ответа:**\n","\n","\"Иван Грозный был первым царем России, правившим с 1547 по 1584 год. Его правление ознаменовалось созданием стрелецкого войска и взятием Казани.\"\n","\n","---\n","\n","\n","- **Вариант без префикса, но с явной инструкцией**\n","\n","```\n","prompt = f\"Ответь на вопрос, используя контекст:\\nКонтекст: {graph_db_context}\\nВопрос: {user_question}\\nОтвет:\"\n","```\n","**Особенности:**\n","\n","Режим работы: Модель интерпретирует запрос как задачу точного QA, где нужно строго следовать контексту.\n","\n","**Преимущества:**\n","\n","Ответы более точные и консервативные.\n","\n","Меньше риск галлюцинаций, так как модель явно ориентирована на предоставленные данные.\n","\n","**Недостатки:**\n","\n","Ответы могут быть сухими или короткими.\n","\n","Если контекст неполный, модель не станет \"додумывать\" информацию.\n","\n","**Пример ответа:**\n","\n","\"Согласно контексту, Иван Грозный стал царем в 1547 году.\"\n","\n","---\n","Когда что использовать?\n","\n","**`<LM>`-вариант, если:**\n","\n","- Нужны развернутые объяснения (например, для образовательного ассистента).\n","\n","- Контекст из графовой БД неполный, и вы хотите, чтобы модель \"додумала\" логичные детали.\n","\n","**Вариант с явной инструкцией, если:**\n","\n","- Требуется максимальная точность (например, в медицинском или юридическом ассистенте).\n","\n","- Контекст из графовой БД полный и достоверный, и нужно избегать отклонений."]},{"cell_type":"markdown","metadata":{"id":"tCFTI8zcK3ZL"},"source":["**Префиксы `<SC1>-<SC6>`** в модели FRED-T5-1.7B предназначены для задач Span Corruption — это разновидность денойзинга (восстановления замаскированных фрагментов текста), где модель учится предсказывать пропущенные части входных данных.\n","\n","Каждый префикс `<SCi>` соответствует разным параметрам маскирования:\n","\n","µ (mu) — средняя длина пропуска (в токенах).\n","\n","r (ratio) — доля замаскированных токенов в тексте.\n"]},{"cell_type":"markdown","metadata":{"id":"jj5htyhKMFF3"},"source":["| Префикс | µ (средняя длина пропуска) | r (доля маскирования) | Когда использовать                     |\n","|---------|----------------------------|-----------------------|----------------------------------------|\n","| `<SC1>` | 3 токена                   | 15%                   | Короткие пропуски, мало шума           |\n","| `<SC2>` | 8 токенов                  | 15%                   | Средние пропуски, мало шума            |\n","| `<SC3>` | 64 токена                  | 15%                   | Длинные пропуски, мало шума            |\n","| `<SC4>` | 3 токена                   | 50%                   | Короткие пропуски, сильный шум         |\n","| `<SC5>` | 8 токенов                  | 50%                   | Средние пропуски, сильный шум          |\n","| `<SC6>` | 64 токена                  | 50%                   | Длинные пропуски, сильный шум          |"]},{"cell_type":"markdown","metadata":{"id":"bsvH8I5sMH_G"},"source":["Примеры использования `<SCi>` префиксов\n","1. **Короткие пропуски** (`SC1>, <SC4>`)\n","Подходит для восстановления отдельных слов или коротких фраз.\n","\n","Пример с `<SC1>` (µ=3, r=15%):\n","\n","```\n","prompt = \"<SC1>Москва — столица <extra_id_0>. Население города составляет около 12 миллионов человек.\"\n","# Модель может предсказать: \"<extra_id_0> России</s>\"\n","Пример с <SC4> (µ=3, r=50%) — больше замаскированных токенов:\n","```\n","```\n","prompt = \"<SC4><extra_id_0> — столица <extra_id_1>. Население <extra_id_2> составляет около 12 миллионов человек.\"\n","# Возможный вывод: \"<extra_id_0> Москва <extra_id_1> России <extra_id_2> города</s>\"\n","```\n","2. **Средние пропуски** (`<SC2>, <SC5>`)\n","Подходит для восстановления предложений или небольших абзацев.\n","\n","Пример с `<SC2>` (µ=8, r=15%):\n","\n","```\n","prompt = \"<SC2>Вторая мировая война началась в <extra_id_0>. Основными участниками были Германия, СССР, США и Великобритания.\"\n","# Модель может предсказать: \"<extra_id_0> 1939 году</s>\"\n","```\n","Пример с `<SC5>` (µ=8, r=50%) — сильное маскирование:\n","\n","```\n","prompt = \"<SC5><extra_id_0> началась в <extra_id_1>. <extra_id_2> участниками были <extra_id_3>.\"\n","# Возможный вывод: \"<extra_id_0> Вторая мировая война <extra_id_1> 1939 году <extra_id_2> Основными <extra_id_3> Германия, СССР, США и Великобритания</s>\"\n","```\n","3. **Длинные пропуски** (`<SC3>, <SC6>`)\n","Подходит для восстановления целых абзацев или сложных структур.\n","\n","Пример с `<SC3>` (µ=64, r=15%):\n","\n","```\n","prompt = \"<SC3>Французская революция <extra_id_0> привела к отмене монархии.\"\n","# Модель может восстановить целый абзац: \"<extra_id_0>, начавшаяся в 1789 году и продолжавшаяся до 1799 года,</s>\"\n","```\n","Пример с `<SC6>` (µ=64, r=50%) — экстремальное маскирование:\n","\n","```\n","prompt = \"<SC6><extra_id_0> <extra_id_1> привела к <extra_id_2>.\"\n","# Возможный вывод: \"<extra_id_0> Французская революция <extra_id_1>, длившаяся с 1789 по 1799 год, <extra_id_2> отмене монархии и установлению республики</s>\"\n","```\n","\n","Возвращаемые запросы и ответы содержат `extra_id_i`, который указывает место в тексте, которое модели необходимо заполнить своим ответом."]},{"cell_type":"markdown","metadata":{"id":"jT3AMD_-PksL"},"source":["# Установка зависимостей"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"xeN5U3RrigcH","executionInfo":{"status":"ok","timestamp":1751817909869,"user_tz":-300,"elapsed":205903,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}},"outputId":"bfa30b49-aee3-42b4-c6f9-fb8c9d770088"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numpy==1.26.0\n","  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging==24.2 in /usr/local/lib/python3.11/dist-packages (24.2)\n","Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (2.32.3)\n","Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Collecting filelock==3.15.1\n","  Downloading filelock-3.15.1-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: typing-extensions==4.14.0 in /usr/local/lib/python3.11/dist-packages (4.14.0)\n","Collecting torch==2.3.1\n","  Downloading torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.3) (2025.6.15)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.3.1 (from torch==2.3.1)\n","  Downloading triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.1) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n","Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filelock-3.15.1-py3-none-any.whl (15 kB)\n","Downloading torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, filelock, triton, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.4.127\n","    Uninstalling nvidia-nvtx-cu12-12.4.127:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.21.5\n","    Uninstalling nvidia-nccl-cu12-2.21.5:\n","      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.18.0\n","    Uninstalling filelock-3.18.0:\n","      Successfully uninstalled filelock-3.18.0\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.6.0+cu124\n","    Uninstalling torch-2.6.0+cu124:\n","      Successfully uninstalled torch-2.6.0+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.3.1 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.0 which is incompatible.\n","torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed filelock-3.15.1 numpy-1.26.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.1 triton-2.3.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"d420e809aa724d1e8ae0e90526c1a114"}},"metadata":{}}],"source":["!pip install --upgrade \\\n","    numpy==1.26.0 \\\n","    packaging==24.2 \\\n","    requests==2.32.3 \\\n","    tqdm==4.67.1 \\\n","    filelock==3.15.1 \\\n","    typing-extensions==4.14.0 \\\n","    torch==2.3.1"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":75551,"status":"ok","timestamp":1751817994571,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"},"user_tz":-300},"id":"z10wGJUHijtb","outputId":"682dbf66-6ed3-43d4-d1fa-178343935d71"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.42.0\n","  Downloading transformers-4.42.0-py3-none-any.whl.metadata (43 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llama-index==0.10.46\n","  Downloading llama_index-0.10.46-py3-none-any.whl.metadata (11 kB)\n","Collecting pyvis==0.3.2\n","  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n","Collecting langchain==0.2.5\n","  Downloading langchain-0.2.5-py3-none-any.whl.metadata (7.0 kB)\n","Collecting pypdf==4.2.0\n","  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n","Collecting langchain-community==0.2.5\n","  Downloading langchain_community-0.2.5-py3-none-any.whl.metadata (2.5 kB)\n","Collecting llama-index-llms-huggingface==0.2.3\n","  Downloading llama_index_llms_huggingface-0.2.3-py3-none-any.whl.metadata (790 bytes)\n","Collecting llama-index-embeddings-huggingface==0.2.2\n","  Downloading llama_index_embeddings_huggingface-0.2.2-py3-none-any.whl.metadata (769 bytes)\n","Collecting llama-index-embeddings-langchain==0.1.2\n","  Downloading llama_index_embeddings_langchain-0.1.2-py3-none-any.whl.metadata (663 bytes)\n","Collecting langchain-huggingface==0.0.3\n","  Downloading langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n","Collecting sentencepiece==0.1.99\n","  Downloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n","Collecting accelerate==0.31.0\n","  Downloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\n","Collecting bitsandbytes==0.43.1\n","  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n","Collecting peft==0.11.1\n","  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n","Collecting llama-index-readers-wikipedia==0.1.4\n","  Downloading llama_index_readers_wikipedia-0.1.4-py3-none-any.whl.metadata (625 bytes)\n","Collecting wikipedia==1.4.0\n","  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting safetensors==0.4.3\n","  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Collecting tokenizers==0.19.1\n","  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting huggingface-hub==0.23.3\n","  Downloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.42.0) (3.15.1)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.42.0) (1.26.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.42.0) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.42.0) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.42.0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.42.0) (2.32.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.42.0) (4.67.1)\n","Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index==0.10.46)\n","  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n","Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index==0.10.46)\n","  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n","Collecting llama-index-core==0.10.46 (from llama-index==0.10.46)\n","  Downloading llama_index_core-0.10.46-py3-none-any.whl.metadata (2.5 kB)\n","Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index==0.10.46)\n","  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n","Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index==0.10.46)\n","  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata (3.8 kB)\n","Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index==0.10.46)\n","  Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl.metadata (8.5 kB)\n","Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index==0.10.46)\n","  Downloading llama_index_llms_openai-0.1.31-py3-none-any.whl.metadata (650 bytes)\n","Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index==0.10.46)\n","  Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl.metadata (728 bytes)\n","Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.46)\n","  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n","Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index==0.10.46)\n","  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n","Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index==0.10.46)\n","  Downloading llama_index_readers_file-0.1.33-py3-none-any.whl.metadata (5.4 kB)\n","Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index==0.10.46)\n","  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n","Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis==0.3.2) (7.34.0)\n","Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.11/dist-packages (from pyvis==0.3.2) (3.1.6)\n","Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis==0.3.2) (4.1.1)\n","Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis==0.3.2) (3.5)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.5) (2.0.41)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.5) (3.11.15)\n","Collecting langchain-core<0.3.0,>=0.2.7 (from langchain==0.2.5)\n","  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n","Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.5)\n","  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.5)\n","  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.5) (2.11.7)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.5) (8.5.0)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.2.5)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting text-generation<0.8.0,>=0.7.0 (from llama-index-llms-huggingface==0.2.3)\n","  Downloading text_generation-0.7.0-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-huggingface==0.2.3) (2.3.1)\n","Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-huggingface==0.2.2) (4.1.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.31.0) (5.9.5)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia==1.4.0) (4.13.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.23.3) (2025.3.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.23.3) (4.14.0)\n","Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.46->llama-index==0.10.46)\n","  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n","Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.46->llama-index==0.10.46)\n","  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama-index==0.10.46) (0.28.1)\n","Collecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core==0.10.46->llama-index==0.10.46)\n","  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl.metadata (760 bytes)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama-index==0.10.46) (1.6.0)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama-index==0.10.46) (3.9.1)\n","Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama-index==0.10.46) (1.93.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama-index==0.10.46) (2.2.2)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama-index==0.10.46) (11.2.1)\n","Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.2.5)\n","  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama-index==0.10.46) (0.9.0)\n","Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.46->llama-index==0.10.46)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core==0.10.46->llama-index==0.10.46) (1.17.2)\n","Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n","Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.14)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n","Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n","Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n","INFO: pip is looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n","Collecting gradio\n","  Downloading gradio-5.35.0-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.10.4 (from gradio)\n","  Downloading gradio_client-1.10.4-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.34.2-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.10.3 (from gradio)\n","  Downloading gradio_client-1.10.3-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.34.1-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.34.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.33.2-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.33.1-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.33.0-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.10.2 (from gradio)\n","  Downloading gradio_client-1.10.2-py3-none-any.whl.metadata (7.1 kB)\n","INFO: pip is still looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n","Collecting gradio\n","  Downloading gradio-5.32.1-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.32.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.30.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.29.1-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.10.0 (from gradio)\n","  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","Collecting gradio\n","  Downloading gradio-5.28.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.27.1-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.9.1 (from gradio)\n","  Downloading gradio_client-1.9.1-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.27.0-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.9.0 (from gradio)\n","  Downloading gradio_client-1.9.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.26.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.8.0 (from gradio)\n","  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.25.1-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.25.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.24.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.23.3-py3-none-any.whl.metadata (16 kB)\n","Collecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n","Collecting gradio\n","  Downloading gradio-5.23.2-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.23.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.22.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.21.0-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.7.2 (from gradio)\n","  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.20.1-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.20.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.19.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.18.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.17.1-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.7.1 (from gradio)\n","  Downloading gradio_client-1.7.1-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.17.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.16.2-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.16.1-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.7.0 (from gradio)\n","  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.16.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.15.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.14.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.13.2-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.6.0 (from gradio)\n","  Downloading gradio_client-1.6.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.13.1-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.13.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.12.0-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.5.4 (from gradio)\n","  Downloading gradio_client-1.5.4-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.11.0-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.5.3 (from gradio)\n","  Downloading gradio_client-1.5.3-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.10.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.9.1-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.5.2 (from gradio)\n","  Downloading gradio_client-1.5.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.9.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.8.0-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.5.1 (from gradio)\n","  Downloading gradio_client-1.5.1-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.7.1-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.5.0 (from gradio)\n","  Downloading gradio_client-1.5.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.7.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.6.0-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.4.3 (from gradio)\n","  Downloading gradio_client-1.4.3-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n","Collecting gradio-client==1.4.2 (from gradio)\n","  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.4.0-py3-none-any.whl.metadata (16 kB)\n","  Downloading gradio-5.3.0-py3-none-any.whl.metadata (15 kB)\n","  Downloading gradio-5.1.0-py3-none-any.whl.metadata (15 kB)\n","Collecting gradio-client==1.4.0 (from gradio)\n","  Downloading gradio_client-1.4.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting gradio\n","  Downloading gradio-5.0.2-py3-none-any.whl.metadata (15 kB)\n","  Downloading gradio-5.0.1-py3-none-any.whl.metadata (15 kB)\n","  Downloading gradio-5.0.0-py3-none-any.whl.metadata (15 kB)\n","  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n","Collecting gradio-client==1.3.0 (from gradio)\n","  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.5.2)\n","Collecting markupsafe~=2.0 (from gradio)\n","  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.0)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n","Collecting pillow>=9.0.0 (from llama-index-core==0.10.46->llama-index==0.10.46)\n","  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n","Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.1)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n","Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.4.0)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n","Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n","  Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.5) (1.20.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.5)\n","  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.46.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core==0.10.46->llama-index==0.10.46) (2025.6.15)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core==0.10.46->llama-index==0.10.46) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core==0.10.46->llama-index==0.10.46) (0.16.0)\n","Collecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface==0.2.2)\n","  Downloading minijinja-2.11.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.4 kB)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis==0.3.2) (75.2.0)\n","Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis==0.3.2)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis==0.3.2) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis==0.3.2) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis==0.3.2) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis==0.3.2) (3.0.51)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis==0.3.2) (2.19.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis==0.3.2) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis==0.3.2) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis==0.3.2) (4.9.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain==0.2.5) (1.33)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.5) (1.0.0)\n","INFO: pip is looking at multiple versions of llama-index-llms-openai to determine which version is compatible with other requirements. This could take a while.\n","Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index==0.10.46)\n","  Downloading llama_index_llms_openai-0.1.30-py3-none-any.whl.metadata (650 bytes)\n","  Downloading llama_index_llms_openai-0.1.29-py3-none-any.whl.metadata (650 bytes)\n","  Downloading llama_index_llms_openai-0.1.28-py3-none-any.whl.metadata (650 bytes)\n","  Downloading llama_index_llms_openai-0.1.27-py3-none-any.whl.metadata (610 bytes)\n","  Downloading llama_index_llms_openai-0.1.26-py3-none-any.whl.metadata (610 bytes)\n","INFO: pip is looking at multiple versions of llama-index-program-openai to determine which version is compatible with other requirements. This could take a while.\n","Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.46)\n","  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl.metadata (715 bytes)\n","Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.46)\n","  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia==1.4.0) (2.7)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.41-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-core==0.10.46->llama-index==0.10.46) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-core==0.10.46->llama-index==0.10.46) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.5) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.5) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.5) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.42.0) (3.4.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.2.2) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.2.2) (1.15.3)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.5) (3.2.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (1.13.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (12.1.105)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (2.3.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (12.5.82)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis==0.3.2) (0.8.4)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain==0.2.5) (3.0.0)\n","Collecting llama-cloud-services>=0.6.41 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.41-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.46->llama-index==0.10.46) (1.5.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-core==0.10.46->llama-index==0.10.46) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-core==0.10.46->llama-index==0.10.46) (0.10.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis==0.3.2) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis==0.3.2) (0.2.13)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.46->llama-index==0.10.46)\n","  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface==0.2.2) (3.6.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface==0.2.3) (1.3.0)\n","Collecting llama-cloud==0.1.30 (from llama-cloud-services>=0.6.41->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud-0.1.30-py3-none-any.whl.metadata (1.2 kB)\n","INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.40-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.40 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.40-py3-none-any.whl.metadata (3.5 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.39-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.39 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.39-py3-none-any.whl.metadata (3.5 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.38-py3-none-any.whl.metadata (6.9 kB)\n","INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n","Collecting llama-cloud-services>=0.6.37 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.38-py3-none-any.whl.metadata (3.5 kB)\n","Collecting llama-cloud==0.1.29 (from llama-cloud-services>=0.6.37->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud-0.1.29-py3-none-any.whl.metadata (1.2 kB)\n","Collecting llama-cloud-services>=0.6.37 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.37-py3-none-any.whl.metadata (3.5 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.37-py3-none-any.whl.metadata (6.9 kB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading llama_parse-0.6.36-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.36 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.36-py3-none-any.whl.metadata (3.5 kB)\n","Collecting llama-cloud==0.1.28 (from llama-cloud-services>=0.6.36->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud-0.1.28-py3-none-any.whl.metadata (1.2 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.35-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.35 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.35-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-cloud==0.1.27 (from llama-cloud-services>=0.6.35->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud-0.1.27-py3-none-any.whl.metadata (1.2 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.34-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.32 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.34-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-cloud==0.1.26 (from llama-cloud-services>=0.6.32->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud-0.1.26-py3-none-any.whl.metadata (1.2 kB)\n","Collecting llama-cloud-services>=0.6.32 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.33-py3-none-any.whl.metadata (3.4 kB)\n","  Downloading llama_cloud_services-0.6.32-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.33-py3-none-any.whl.metadata (6.9 kB)\n","  Downloading llama_parse-0.6.32-py3-none-any.whl.metadata (6.9 kB)\n","  Downloading llama_parse-0.6.31-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.31 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.31-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.30-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.30 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.30-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-cloud==0.1.23 (from llama-cloud-services>=0.6.30->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud-0.1.23-py3-none-any.whl.metadata (1.1 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.28-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.28 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.29-py3-none-any.whl.metadata (3.4 kB)\n","  Downloading llama_cloud_services-0.6.28-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.27-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.27 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.27-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.26-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.26 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.26-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.25-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.24 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.25-py3-none-any.whl.metadata (3.4 kB)\n","  Downloading llama_cloud_services-0.6.24-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.24-py3-none-any.whl.metadata (6.9 kB)\n","  Downloading llama_parse-0.6.23-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.23 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.23-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-cloud==0.1.22 (from llama-cloud-services>=0.6.23->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud-0.1.22-py3-none-any.whl.metadata (1.2 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.22-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.22 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.22-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-cloud==0.1.19 (from llama-cloud-services>=0.6.22->llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.21-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.21 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.21-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.20-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.20 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.20-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.18-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.17 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.19-py3-none-any.whl.metadata (3.4 kB)\n","  Downloading llama_cloud_services-0.6.18-py3-none-any.whl.metadata (3.4 kB)\n","  Downloading llama_cloud_services-0.6.17-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.16-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.16 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.16-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.12-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.12 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.15-py3-none-any.whl.metadata (3.4 kB)\n","  Downloading llama_cloud_services-0.6.14-py3-none-any.whl.metadata (3.4 kB)\n","  Downloading llama_cloud_services-0.6.12-py3-none-any.whl.metadata (3.4 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.9-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.9 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.11-py3-none-any.whl.metadata (3.5 kB)\n","  Downloading llama_cloud_services-0.6.10-py3-none-any.whl.metadata (3.5 kB)\n","  Downloading llama_cloud_services-0.6.9-py3-none-any.whl.metadata (2.9 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.4.post1-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.4 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.8-py3-none-any.whl.metadata (2.9 kB)\n","  Downloading llama_cloud_services-0.6.7-py3-none-any.whl.metadata (2.9 kB)\n","  Downloading llama_cloud_services-0.6.6-py3-none-any.whl.metadata (2.9 kB)\n","  Downloading llama_cloud_services-0.6.5-py3-none-any.whl.metadata (2.9 kB)\n","  Downloading llama_cloud_services-0.6.4-py3-none-any.whl.metadata (2.9 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.4-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.3 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.3-py3-none-any.whl.metadata (2.9 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.2-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.2 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.2-py3-none-any.whl.metadata (2.8 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.1-py3-none-any.whl.metadata (6.9 kB)\n","Collecting llama-cloud-services>=0.6.1 (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.1-py3-none-any.whl.metadata (2.7 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.6.0-py3-none-any.whl.metadata (6.8 kB)\n","Collecting llama-cloud-services (from llama-parse>=0.4.0->llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_cloud_services-0.6.0-py3-none-any.whl.metadata (2.7 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.46)\n","  Downloading llama_parse-0.5.20-py3-none-any.whl.metadata (6.9 kB)\n","INFO: pip is looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n","  Downloading llama_parse-0.5.19-py3-none-any.whl.metadata (7.0 kB)\n","  Downloading llama_parse-0.5.18-py3-none-any.whl.metadata (7.0 kB)\n","  Downloading llama_parse-0.5.17-py3-none-any.whl.metadata (7.0 kB)\n","  Downloading llama_parse-0.5.16-py3-none-any.whl.metadata (7.0 kB)\n","  Downloading llama_parse-0.5.15-py3-none-any.whl.metadata (7.0 kB)\n","  Downloading llama_parse-0.5.14-py3-none-any.whl.metadata (6.9 kB)\n","  Downloading llama_parse-0.5.13-py3-none-any.whl.metadata (6.9 kB)\n","INFO: pip is still looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n","  Downloading llama_parse-0.5.12-py3-none-any.whl.metadata (6.9 kB)\n","  Downloading llama_parse-0.5.11-py3-none-any.whl.metadata (6.9 kB)\n","  Downloading llama_parse-0.5.10-py3-none-any.whl.metadata (6.9 kB)\n","  Downloading llama_parse-0.5.9-py3-none-any.whl.metadata (6.9 kB)\n","  Downloading llama_parse-0.5.8-py3-none-any.whl.metadata (6.4 kB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading llama_parse-0.5.7-py3-none-any.whl.metadata (6.4 kB)\n","  Downloading llama_parse-0.5.6-py3-none-any.whl.metadata (6.1 kB)\n","  Downloading llama_parse-0.5.5-py3-none-any.whl.metadata (6.1 kB)\n","  Downloading llama_parse-0.5.4-py3-none-any.whl.metadata (6.1 kB)\n","  Downloading llama_parse-0.5.3-py3-none-any.whl.metadata (4.5 kB)\n","  Downloading llama_parse-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n","  Downloading llama_parse-0.5.1-py3-none-any.whl.metadata (4.5 kB)\n","  Downloading llama_parse-0.5.0-py3-none-any.whl.metadata (4.4 kB)\n","  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading transformers-4.42.0-py3-none-any.whl (9.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index-0.10.46-py3-none-any.whl (6.8 kB)\n","Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain-0.2.5-py3-none-any.whl (974 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_community-0.2.5-py3-none-any.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_llms_huggingface-0.2.3-py3-none-any.whl (10 kB)\n","Downloading llama_index_embeddings_huggingface-0.2.2-py3-none-any.whl (7.2 kB)\n","Downloading llama_index_embeddings_langchain-0.1.2-py3-none-any.whl (2.5 kB)\n","Downloading langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\n","Downloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_readers_wikipedia-0.1.4-py3-none-any.whl (2.3 kB)\n","Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_core-0.10.46-py3-none-any.whl (15.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading langchain_core-0.2.43-py3-none-any.whl (397 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.1/397.1 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n","Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n","Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n","Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n","Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n","Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_llms_openai-0.1.26-py3-none-any.whl (11 kB)\n","Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\n","Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n","Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n","Downloading llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\n","Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n","Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n","Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n","Downloading text_generation-0.7.0-py3-none-any.whl (12 kB)\n","Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n","Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n","Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n","Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading minijinja-2.11.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n","Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n","Building wheels for collected packages: wikipedia\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=9b342a8258d0d40fb374c559d0960ecc0a44dd028838deb18ad470d1935ac3eb\n","  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n","Successfully built wikipedia\n","Installing collected packages: striprtf, sentencepiece, dirtyjson, websockets, tomlkit, tenacity, safetensors, pypdf, pillow, mypy-extensions, minijinja, marshmallow, markupsafe, jedi, deprecated, aiofiles, wikipedia, typing-inspect, huggingface-hub, tokenizers, text-generation, pyvis, llamaindex-py-client, langsmith, gradio-client, dataclasses-json, transformers, llama-index-legacy, llama-index-core, langchain-core, gradio, bitsandbytes, accelerate, peft, llama-parse, llama-index-readers-wikipedia, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-embeddings-langchain, langchain-text-splitters, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-llms-huggingface, llama-index-embeddings-huggingface, llama-index-cli, llama-index-agent-openai, langchain-huggingface, langchain, llama-index-program-openai, langchain-community, llama-index-question-gen-openai, llama-index\n","  Attempting uninstall: sentencepiece\n","    Found existing installation: sentencepiece 0.2.0\n","    Uninstalling sentencepiece-0.2.0:\n","      Successfully uninstalled sentencepiece-0.2.0\n","  Attempting uninstall: websockets\n","    Found existing installation: websockets 15.0.1\n","    Uninstalling websockets-15.0.1:\n","      Successfully uninstalled websockets-15.0.1\n","  Attempting uninstall: tomlkit\n","    Found existing installation: tomlkit 0.13.3\n","    Uninstalling tomlkit-0.13.3:\n","      Successfully uninstalled tomlkit-0.13.3\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 8.5.0\n","    Uninstalling tenacity-8.5.0:\n","      Successfully uninstalled tenacity-8.5.0\n","  Attempting uninstall: safetensors\n","    Found existing installation: safetensors 0.5.3\n","    Uninstalling safetensors-0.5.3:\n","      Successfully uninstalled safetensors-0.5.3\n","  Attempting uninstall: pillow\n","    Found existing installation: pillow 11.2.1\n","    Uninstalling pillow-11.2.1:\n","      Successfully uninstalled pillow-11.2.1\n","  Attempting uninstall: markupsafe\n","    Found existing installation: MarkupSafe 3.0.2\n","    Uninstalling MarkupSafe-3.0.2:\n","      Successfully uninstalled MarkupSafe-3.0.2\n","  Attempting uninstall: aiofiles\n","    Found existing installation: aiofiles 24.1.0\n","    Uninstalling aiofiles-24.1.0:\n","      Successfully uninstalled aiofiles-24.1.0\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.33.1\n","    Uninstalling huggingface-hub-0.33.1:\n","      Successfully uninstalled huggingface-hub-0.33.1\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.21.2\n","    Uninstalling tokenizers-0.21.2:\n","      Successfully uninstalled tokenizers-0.21.2\n","  Attempting uninstall: langsmith\n","    Found existing installation: langsmith 0.4.4\n","    Uninstalling langsmith-0.4.4:\n","      Successfully uninstalled langsmith-0.4.4\n","  Attempting uninstall: gradio-client\n","    Found existing installation: gradio_client 1.10.1\n","    Uninstalling gradio_client-1.10.1:\n","      Successfully uninstalled gradio_client-1.10.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.53.0\n","    Uninstalling transformers-4.53.0:\n","      Successfully uninstalled transformers-4.53.0\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.67\n","    Uninstalling langchain-core-0.3.67:\n","      Successfully uninstalled langchain-core-0.3.67\n","  Attempting uninstall: gradio\n","    Found existing installation: gradio 5.31.0\n","    Uninstalling gradio-5.31.0:\n","      Successfully uninstalled gradio-5.31.0\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 1.8.1\n","    Uninstalling accelerate-1.8.1:\n","      Successfully uninstalled accelerate-1.8.1\n","  Attempting uninstall: peft\n","    Found existing installation: peft 0.15.2\n","    Uninstalling peft-0.15.2:\n","      Successfully uninstalled peft-0.15.2\n","  Attempting uninstall: langchain-text-splitters\n","    Found existing installation: langchain-text-splitters 0.3.8\n","    Uninstalling langchain-text-splitters-0.3.8:\n","      Successfully uninstalled langchain-text-splitters-0.3.8\n","  Attempting uninstall: langchain\n","    Found existing installation: langchain 0.3.26\n","    Uninstalling langchain-0.3.26:\n","      Successfully uninstalled langchain-0.3.26\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-genai 1.23.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 12.0 which is incompatible.\n","dataproc-spark-connect 0.7.5 requires websockets>=14.0, but you have websockets 12.0 which is incompatible.\n","torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.3.1 which is incompatible.\n","diffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.23.3 which is incompatible.\n","yfinance 0.2.64 requires websockets>=13.0, but you have websockets 12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.31.0 aiofiles-23.2.1 bitsandbytes-0.43.1 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 gradio-4.44.1 gradio-client-1.3.0 huggingface-hub-0.23.3 jedi-0.19.2 langchain-0.2.5 langchain-community-0.2.5 langchain-core-0.2.43 langchain-huggingface-0.0.3 langchain-text-splitters-0.2.4 langsmith-0.1.147 llama-index-0.10.46 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.46 llama-index-embeddings-huggingface-0.2.2 llama-index-embeddings-langchain-0.1.2 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48.post4 llama-index-llms-huggingface-0.2.3 llama-index-llms-openai-0.1.26 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.33 llama-index-readers-llama-parse-0.1.6 llama-index-readers-wikipedia-0.1.4 llama-parse-0.4.9 llamaindex-py-client-0.1.19 markupsafe-2.1.5 marshmallow-3.26.1 minijinja-2.11.0 mypy-extensions-1.1.0 peft-0.11.1 pillow-10.4.0 pypdf-4.2.0 pyvis-0.3.2 safetensors-0.4.3 sentencepiece-0.1.99 striprtf-0.0.26 tenacity-8.3.0 text-generation-0.7.0 tokenizers-0.19.1 tomlkit-0.12.0 transformers-4.42.0 typing-inspect-0.9.0 websockets-12.0 wikipedia-1.4.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]},"id":"a4675ffec7444a518fed24f7e03e718a"}},"metadata":{}}],"source":["!pip install \\\n","    transformers==4.42.0 \\\n","    llama-index==0.10.46 \\\n","    pyvis==0.3.2 \\\n","    langchain==0.2.5 \\\n","    pypdf==4.2.0 \\\n","    langchain-community==0.2.5 \\\n","    llama-index-llms-huggingface==0.2.3 \\\n","    llama-index-embeddings-huggingface==0.2.2 \\\n","    llama-index-embeddings-langchain==0.1.2 \\\n","    langchain-huggingface==0.0.3 \\\n","    sentencepiece==0.1.99 \\\n","    accelerate==0.31.0 \\\n","    bitsandbytes==0.43.1 \\\n","    peft==0.11.1 \\\n","    llama-index-readers-wikipedia==0.1.4 \\\n","    wikipedia==1.4.0 \\\n","    safetensors==0.4.3 \\\n","    tokenizers==0.19.1 \\\n","    huggingface-hub==0.23.3 \\\n","    gradio"]},{"cell_type":"markdown","metadata":{"id":"mVR72EyrSv53"},"source":["## Импорт"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":31789,"status":"ok","timestamp":1751818032799,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"},"user_tz":-300},"id":"RREk_ZneSzef"},"outputs":[],"source":["from llama_index.core import SimpleDirectoryReader\n","from llama_index.core import KnowledgeGraphIndex\n","from llama_index.core import Settings\n","from llama_index.core.graph_stores import SimpleGraphStore\n","from llama_index.core import StorageContext\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","from llama_index.llms.huggingface import HuggingFaceLLM\n","from llama_index.core.prompts import PromptTemplate\n","from llama_index.embeddings.langchain import LangchainEmbedding\n","from transformers import GPT2Tokenizer, T5ForConditionalGeneration\n","from peft.peft_model import PeftModel\n","from peft.config import PeftConfig\n","from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n","import torch\n","from pyvis.network import Network\n","from huggingface_hub import login\n","from google.colab import userdata"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Nlw7tBA5S7rG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751818033781,"user_tz":-300,"elapsed":983,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}},"outputId":"b1aec4b4-ddf8-4ff8-c0a2-60a7ab9791bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Token is valid (permission: write).\n","Your token has been saved in your configured git credential helpers (store).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["HF_TOKEN=userdata.get('HF_TOKEN')\n","# Вставьте ваш токен (здесь указан временный токен)\n","login(HF_TOKEN, add_to_git_credential=True)"]},{"cell_type":"markdown","source":["## Настройка модели"],"metadata":{"id":"i8_rV0nxZukr"}},{"cell_type":"code","source":["tokenizer = GPT2Tokenizer.from_pretrained('ai-forever/FRED-T5-1.7B',eos_token='</s>')\n","model = T5ForConditionalGeneration.from_pretrained('ai-forever/FRED-T5-1.7B')\n","device='cuda'\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["bb5af6eac3624e3ba2a05452f0b8a420","eb16602da90540f296fd2d9d02a5a0b8","a2bc72231b544702af9470d931ac39c4","86bd52930d534d8e8634a638c0290fd6","634277feb5fa4f858afef201e3b94ecc","4b8f8efc5f3f4a46b44bd8c525b47a4a","0e5d920a5be04626b45979ad91754548","bf14a762a0e14212901912715dd50dc5","cc6f7adc18634622935940d31ba2e140","ae6befedefbc49dc8020383adbabb329","39dd2df7ffd246fb8101fd4e2eff54e1","d245005f8faf4d88a1620da9f71e2048","ebad3572fe5c44c98e8e18b7761ea4e7","ddce5971ce6a43e7afd28d60a499023b","a827a8cf2046440dbdc256121ef7f43c","e889b9ecbffb4c5ebc42f65a55a99d28","53812c74d1f245d8945d1848736690b2","b824db36ad614827a42aaf2b8f9c298f","7d9b515c5eef492c8bc3586a17481e84","894e1e16bce046408b3d1e3055a44911","d6e144f1f29841a6b39306a039f5fa39","b5df6dabfadf4f1ca2196ca8f443dd66","39f9eb6b0c7042b498996dfdf5eb9b7f","9c0e2a93eccb47cbb62129088a22be0f","70e728b6a7fd470f835f31979d9eb166","46cca5a2a8864e28b6d6224116248f56","26ad037d39834250b3809596122ccb9b","c70b1c1311ee417eb13c168bff8e824c","b88f4569bcdf4b029224f6da5f5e896a","9f0827991bd447cab3c73cdafdc627d9","8b22d00fe31d421d98c18ab68dc6a50b","88ed0153a839405382cebcf26abd57d9","1787b323a9954e9cb04c0283680f21d2","e4f792aab94945f48345469f8601ab7d","3d58c62ce71846b9949ba9da16730fd8","c8ef12ae89da46d78754d061e419f408","53e5e666dbbe4bb7a8ee22c811262edd","08356dd7056a4b2a8551c6b575adf0e4","80ca6e695cb14ed8839726b7aa71fc8e","778b60f0bf994ed7b88adf942d92ecb3","471971eb725e42cca2d2035c0c96c71f","b1d0e79e75dd40b0a804b641574cf320","a131e5025c0044c295a8d1fcdeff75f8","0086558e0d1b4ff0b225e9448f4a239f"]},"id":"YUdVsTkb6_FO","executionInfo":{"status":"ok","timestamp":1751818419673,"user_tz":-300,"elapsed":327868,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}},"outputId":"008e0039-43a1-49b6-cc73-225450d378ae"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["vocab.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb5af6eac3624e3ba2a05452f0b8a420"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d245005f8faf4d88a1620da9f71e2048"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/653 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39f9eb6b0c7042b498996dfdf5eb9b7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/6.96G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4f792aab94945f48345469f8601ab7d"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(50364, 1536)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(50364, 1536)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1536, out_features=1536, bias=False)\n","              (k): Linear(in_features=1536, out_features=1536, bias=False)\n","              (v): Linear(in_features=1536, out_features=1536, bias=False)\n","              (o): Linear(in_features=1536, out_features=1536, bias=False)\n","              (relative_attention_bias): Embedding(32, 24)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n","              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-23): 23 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1536, out_features=1536, bias=False)\n","              (k): Linear(in_features=1536, out_features=1536, bias=False)\n","              (v): Linear(in_features=1536, out_features=1536, bias=False)\n","              (o): Linear(in_features=1536, out_features=1536, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n","              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(50364, 1536)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1536, out_features=1536, bias=False)\n","              (k): Linear(in_features=1536, out_features=1536, bias=False)\n","              (v): Linear(in_features=1536, out_features=1536, bias=False)\n","              (o): Linear(in_features=1536, out_features=1536, bias=False)\n","              (relative_attention_bias): Embedding(32, 24)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1536, out_features=1536, bias=False)\n","              (k): Linear(in_features=1536, out_features=1536, bias=False)\n","              (v): Linear(in_features=1536, out_features=1536, bias=False)\n","              (o): Linear(in_features=1536, out_features=1536, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n","              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-23): 23 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=1536, out_features=1536, bias=False)\n","              (k): Linear(in_features=1536, out_features=1536, bias=False)\n","              (v): Linear(in_features=1536, out_features=1536, bias=False)\n","              (o): Linear(in_features=1536, out_features=1536, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=1536, out_features=1536, bias=False)\n","              (k): Linear(in_features=1536, out_features=1536, bias=False)\n","              (v): Linear(in_features=1536, out_features=1536, bias=False)\n","              (o): Linear(in_features=1536, out_features=1536, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseGatedActDense(\n","              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n","              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n","              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): NewGELUActivation()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=1536, out_features=50364, bias=False)\n",")"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["## Проверка работы"],"metadata":{"id":"M6T8NXahkWXR"}},{"cell_type":"code","source":["#Prefix <LM>\n","lm_text='<LM>Принялся Кутузов рассказывать свою историю как он сюда попал. Началось'\n","input_ids=torch.tensor([tokenizer.encode(lm_text)]).to(device)\n","outputs=model.generate(input_ids, eos_token_id=tokenizer.eos_token_id, early_stopping=True)\n","print(tokenizer.decode(outputs[0][1:]))\n","\n","# print result: с того, что он был в армии, служил в артиллерии</s>.\n","\n","#Prefix <SC1>\n","lm_text='<SC1>Принялся Кутузов рассказывать свою историю <extra_id_0>. Началось с того, что он был в армии, служил в артиллерии.'\n","input_ids=torch.tensor([tokenizer.encode(lm_text)]).to(device)\n","outputs=model.generate(input_ids,eos_token_id=tokenizer.eos_token_id,early_stopping=True)\n","print(tokenizer.decode(outputs[0][1:]))\n","\n","#print result: '<extra_id_0>, как он воевал</s>'\n","\n","# Prefix <SC5>\n","lm_text='<SC5>Принялся Кутузов рассказывать свою историю <extra_id_0>. Началось с того, что он был в армии, служил в артиллерии.'\n","input_ids=torch.tensor([tokenizer.encode(lm_text)]).to(device)\n","outputs=model.generate(input_ids,eos_token_id=tokenizer.eos_token_id,early_stopping=True)\n","tokenizer.decode(outputs[0][1:])\n","\n","#print result: '<extra_id_0>, как он стал генералом</s>'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":160},"id":"2HaXuywI5df2","executionInfo":{"status":"ok","timestamp":1751704094130,"user_tz":-300,"elapsed":2112,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}},"outputId":"9aad5b39-0db6-4bb5-8549-9dbfd98ae8f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":[" с того, что он был в армии, служил в артиллерии.</s>\n","<extra_id_0>  и рассказывать интересно</s>\n"]},{"output_type":"execute_result","data":{"text/plain":["'<extra_id_0> \\n— Вот как было дело</s>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["lm_text='<LM>Задание: Дай точное определение термина.\\nТермин: компьютерные нейросети\\nОпределение:'\n","input_ids=torch.tensor([tokenizer.encode(lm_text)]).to(device)\n","outputs=model.generate(input_ids,eos_token_id=tokenizer.eos_token_id,early_stopping=True, max_new_tokens=200)\n","print(tokenizer.decode(outputs[0][1:]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XkMfJwtCAdLE","executionInfo":{"status":"ok","timestamp":1751704099579,"user_tz":-300,"elapsed":900,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}},"outputId":"6b4a3293-c132-47d5-bd10-6b6334d2f9f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" компьютерные нейросети - это системы, которые могут обучаться и самообучаться.</s>\n"]}]},{"cell_type":"code","source":["#Prefix <SC1>\n","lm_text='<SC1>Дай определение: Нейросети - <extra_id_0>'\n","input_ids=torch.tensor([tokenizer.encode(lm_text)]).to(device)\n","outputs=model.generate(input_ids,eos_token_id=tokenizer.eos_token_id,early_stopping=True, max_new_tokens=100)\n","print(tokenizer.decode(outputs[0][1:]))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jPnhQC48AoVk","executionInfo":{"status":"ok","timestamp":1751704108953,"user_tz":-300,"elapsed":288,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}},"outputId":"20f12e34-f8eb-4754-ece1-18906d57f775"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<extra_id_0>  Искусственный интеллект.</s>\n"]}]},{"cell_type":"code","source":["# Prefix <SC5>\n","lm_text='<SC5>Дай развернутое определение: Нейросеть - <extra_id_0>'\n","input_ids=torch.tensor([tokenizer.encode(lm_text)]).to(device)\n","outputs=model.generate(input_ids,eos_token_id=tokenizer.eos_token_id,early_stopping=True, max_new_tokens=100)\n","tokenizer.decode(outputs[0][1:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"yzduS1IqDPbS","executionInfo":{"status":"ok","timestamp":1751659863223,"user_tz":-300,"elapsed":1005,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}},"outputId":"afc96f4b-ce96-40b0-c5ee-28bd1bf6466c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<extra_id_0>  Искусственный интеллект, который может выполнять сложные задачи.</s>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# Prefix <LM>\n","lm_text='<LM>Столица Франции - <extra_id_0>, а Германии - <extra_id_1>. Обе находятся в <extra_id_2>'\n","input_ids=torch.tensor([tokenizer.encode(lm_text)]).to(device)\n","outputs=model.generate(input_ids,eos_token_id=tokenizer.eos_token_id,early_stopping=True, max_new_tokens=100)\n","tokenizer.decode(outputs[0][1:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"nlRUvW6JFFia","executionInfo":{"status":"ok","timestamp":1751660538335,"user_tz":-300,"elapsed":934,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}},"outputId":"ce15afd9-7e6b-4ebf-fa6f-4a1932f925fa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<extra_id_0> \\nПариж <extra_id_1> \\nБерлин <extra_id_2> \\nЕвропе.</s>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["def format_definition_request(term):\n","    return f\"\"\"<LM>Система: Ты - эксперт по терминологии. Дай строгое определение.\n","Пользователь: Определи термин \"{term}\"\n","Ассистент: {term} - это\"\"\"\n","\n","# Использование\n","prompt = format_definition_request(\"Нейросети\")\n","input_ids=torch.tensor([tokenizer.encode(prompt)]).to(device)\n","outputs=model.generate(input_ids,eos_token_id=tokenizer.eos_token_id,early_stopping=True, max_new_tokens=100)\n","tokenizer.decode(outputs[0][1:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"1JG4xqmJWZai","executionInfo":{"status":"ok","timestamp":1751704135506,"user_tz":-300,"elapsed":1877,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}},"outputId":"64e7cdfa-a3d8-4899-cb50-c485e73bd234"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["' нейронные сети, которые могут обучаться.</s>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["Для генерации ответов на натуральные вопросы с поиском по документам в FRED-T5-1.7B оптимально использовать префикс `<LM>` (Language Modeling), а не `<SC>`-префиксы, которые требуют явного указания пропусков (что не подходит для свободных вопросов пользователя)."],"metadata":{"id":"pjOAWUx5KIfO"}},{"cell_type":"markdown","source":["## Форматирование для FRED-T5"],"metadata":{"id":"z85n258WhLnn"}},{"cell_type":"code","source":["def messages_to_prompt(messages):\n","    \"\"\"Адаптация формата <LM> для диалога\"\"\"\n","    prompt = \"<LM>\"\n","    for message in messages:\n","        if message.role == 'system':\n","            prompt += f\"<s>System: {message.content}</s>\\n\"\n","        elif message.role == 'user':\n","            prompt += f\"<s>User: {message.content}</s>\\n\"\n","        elif message.role == 'assistant':\n","            prompt += f\"<s>Assistant: {message.content}</s>\\n\"\n","    return prompt + \"<s>Assistant:\\n\"\n","\n","def completion_to_prompt(completion):\n","    \"\"\"Форматирование одиночных запросов\"\"\"\n","    return f\"<LM><s>System:</s>\\n<s>User: {completion}</s>\\n<s>Assistant:</s>\\n<s>Assistant:\""],"metadata":{"id":"wa88KDdphSF-","executionInfo":{"status":"ok","timestamp":1751790413175,"user_tz":-300,"elapsed":75,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Инициализация LLM в LlamaIndex"],"metadata":{"id":"tiPeU3wui-2Z"}},{"cell_type":"code","source":["llm = HuggingFaceLLM(\n","    model=model,\n","    tokenizer=tokenizer,\n","    model_name='ai-forever/FRED-T5-1.7B',\n","    #context_window=2048,\n","    max_new_tokens=512,\n","    generate_kwargs={\n","        \"early_stopping\": True,\n","        \"temperature\": 0.3,\n","        \"top_k\": 30,\n","        \"top_p\": 0.9,\n","        \"repetition_penalty\": 1.1,\n","        \"do_sample\": True,\n","        \"eos_token_id\": tokenizer.eos_token_id,\n","        \"pad_token_id\": tokenizer.pad_token_id,\n","    },\n","    messages_to_prompt=messages_to_prompt,\n","    completion_to_prompt=completion_to_prompt,\n","    device_map=\"cuda\",\n",")"],"metadata":{"id":"y_K63sFcjGDK","executionInfo":{"status":"ok","timestamp":1751790419631,"user_tz":-300,"elapsed":99,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["response = llm.complete(\"Задание: Расскажи про Кутузова для доклада\", reset_context=True)\n","print(response.text)  # вывод сгенерированного текста"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WjdLCmtSuWH5","executionInfo":{"status":"ok","timestamp":1751707771423,"user_tz":-300,"elapsed":2720,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}},"outputId":"2cc591cd-7dbb-4b11-d987-f5ddfb7c6ef4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" 1813 году Кутузов был назначен главнокомандующим. В этом же году он участвовал в сражении при Бородино.\n","Кутузов был одним из самых выдающихся полководцев Отечественной войны 1812 года. Он командовал армией во время сражения под Москвой.\n","Память о нем сохранилась в виде памятника на Бородинском поле.\n"]}]},{"cell_type":"code","source":["prompt = completion_to_prompt(\"расскажи про Кутузова\")\n","print(prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVKRJx2wzZAB","executionInfo":{"status":"ok","timestamp":1751706593024,"user_tz":-300,"elapsed":29,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}},"outputId":"a9081886-e17e-4f3d-d59d-820e206c3262"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<LM><s>System:</s>\n","<s>User: расскажи про Кутузова</s>\n","<s>Assistant:</s>\n","<s>Assistant:\n"]}]},{"cell_type":"markdown","source":["## Настройки окружения LlamaIndex"],"metadata":{"id":"wV197pHO7l5f"}},{"cell_type":"code","source":["from langchain_huggingface  import HuggingFaceEmbeddings\n","embed_model = LangchainEmbedding(\n","  HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n","                        model_kwargs={\"device\": \"cuda\"},\n","                        encode_kwargs={\"batch_size\": 32}\n","                        )\n",")"],"metadata":{"id":"5bxU9LEK7NH9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Настройка ServiceContext (глобальная настройка параметров LLM)\n","Settings.llm = llm\n","Settings.embed_model = embed_model\n","Settings.chunk_size = 512"],"metadata":{"id":"n9MkafRB7kr4","executionInfo":{"status":"aborted","timestamp":1751793444502,"user_tz":-300,"elapsed":22728,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Создаем простое графовое хранилище\n","graph_store = SimpleGraphStore()\n","\n","# Устанавливаем информацию о хранилище в StorageContext\n","storage_context = StorageContext.from_defaults(graph_store=graph_store)"],"metadata":{"id":"kervM87W8CPE","executionInfo":{"status":"ok","timestamp":1751792017300,"user_tz":-300,"elapsed":131,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Проблемы с моделью и решения"],"metadata":{"id":"abHFXEAl4R9B"}},{"cell_type":"markdown","source":["Загрузить квантованную модель не получилось из-за конфликта библиотеки BytesandBitsConfig и Triton, однако, как оказалось, полная модель смогла запуститься без проблем на бесплатно предоставляемом железе colab. По этому использовал метод, указанный в инструкции на HF.\n","\n","При попытке несколько раз выполнить генерацию ответа, модель постепенно начинала галлюцинировать, причина - переполнение кешированного контекста HuggingFaceLLM. Помог параметр `reset_context=True` в запросе `llm.complete()`\n","\n","Долго пытался подобрать правильное форматирование запроса для модели - верный формат: `<LM>` тег должен начинать весь промпт, включая `System` и `Assistant`, а не только текст пользователя. Тем не менее артефакты в генерации встречаются - начало"],"metadata":{"id":"vU2Tm8oh4Xlf"}},{"cell_type":"markdown","source":["## Добавление документов pdf в базу"],"metadata":{"id":"2jlu9XUe7YI4"}},{"cell_type":"markdown","source":["Работать будем с простыми книгами в формате pdf - по этому нет необходимости в сложных ридерах. PyMuPDF простой и быстрый ридер - подойдет для таких целей."],"metadata":{"id":"-UnRKqmf2Zrh"}},{"cell_type":"code","source":["!pip install pymupdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HWYn5blO9AKv","executionInfo":{"status":"ok","timestamp":1751818428109,"user_tz":-300,"elapsed":8438,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}},"outputId":"1c05ab4b-78da-4f17-ed98-5eb35ab447f3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pymupdf\n","  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n","Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pymupdf\n","Successfully installed pymupdf-1.26.3\n"]}]},{"cell_type":"markdown","source":["# Интерфейс и сборка"],"metadata":{"id":"yKqSsVso8SwQ"}},{"cell_type":"code","source":["!pip install --upgrade gradio==3.50.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NN5pjp-vBQxZ","executionInfo":{"status":"ok","timestamp":1751818439562,"user_tz":-300,"elapsed":11451,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}},"outputId":"a277661a-1eab-46d2-8f33-661951310bed"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio==3.50.2\n","  Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (23.2.1)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (5.5.0)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.115.14)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.6.0)\n","Collecting gradio-client==0.6.1 (from gradio==3.50.2)\n","  Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.23.3)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (6.5.2)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (3.1.6)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.1.5)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (3.10.0)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (1.26.0)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (3.10.18)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.2.2)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (10.4.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.11.7)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.25.1)\n","Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.0.20)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (6.0.2)\n","Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.32.3)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (2.10.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (4.14.0)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.50.2) (0.35.0)\n","Collecting websockets<12.0,>=10.0 (from gradio==3.50.2)\n","  Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==0.6.1->gradio==3.50.2) (2025.3.2)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (4.24.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2) (1.45.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (3.15.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50.2) (4.67.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==3.50.2) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==3.50.2) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.2) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.0->gradio==3.50.2) (2025.6.15)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (8.2.1)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2) (0.16.0)\n","Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->gradio==3.50.2) (0.46.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.50.2) (4.9.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.50.2) (1.0.9)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2) (0.26.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.50.2) (1.17.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->gradio==3.50.2) (1.3.1)\n","Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: websockets, gradio-client, gradio\n","  Attempting uninstall: websockets\n","    Found existing installation: websockets 12.0\n","    Uninstalling websockets-12.0:\n","      Successfully uninstalled websockets-12.0\n","  Attempting uninstall: gradio-client\n","    Found existing installation: gradio_client 1.3.0\n","    Uninstalling gradio_client-1.3.0:\n","      Successfully uninstalled gradio_client-1.3.0\n","  Attempting uninstall: gradio\n","    Found existing installation: gradio 4.44.1\n","    Uninstalling gradio-4.44.1:\n","      Successfully uninstalled gradio-4.44.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-genai 1.23.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\n","dataproc-spark-connect 0.7.5 requires websockets>=14.0, but you have websockets 11.0.3 which is incompatible.\n","yfinance 0.2.64 requires websockets>=13.0, but you have websockets 11.0.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gradio-3.50.2 gradio-client-0.6.1 websockets-11.0.3\n"]}]},{"cell_type":"code","source":["import gradio as gr\n","import os\n","import traceback\n","import time\n","from llama_index.readers.file import PyMuPDFReader\n","from llama_index.core.query_engine import RetrieverQueryEngine\n","import tempfile\n","from langchain_huggingface  import HuggingFaceEmbeddings\n","\n","torch.cuda.empty_cache()  # Очищаем кэш GPU\n","torch.backends.cudnn.benchmark = True  # Оптимизация для CUDA\n","\n","embed_model = LangchainEmbedding(\n","    HuggingFaceEmbeddings(\n","        model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n","        model_kwargs={\n","            \"device\": \"cuda\",\n","            \"trust_remote_code\": True\n","        },\n","        encode_kwargs={\n","            \"batch_size\": 64,  # Увеличиваем batch size\n","            \"normalize_embeddings\": True,  # Включаем нормализацию\n","            \"show_progress_bar\": True\n","        }\n","    )\n",")\n","\n","# Глобальные переменные\n","current_index = None\n","DEFAULT_SYSTEM_PROMPT = \"Ты помощник обработки статей, отвечай только основываясь на данных из статьи. Если не знаешь ответ - напиши 'нет данных', не придумывай.\"\n","\n","# Доработанные функции промптов\n","def messages_to_prompt(messages, system_prompt=DEFAULT_SYSTEM_PROMPT):\n","    prompt = \"<LM>\"\n","    if system_prompt:\n","        prompt += f\"<s>System: {system_prompt}</s>\\n\"\n","    for message in messages:\n","        if message.role == 'system':\n","            prompt += f\"<s>System: {message.content}</s>\\n\"\n","        elif message.role == 'user':\n","            prompt += f\"<s>User: {message.content}</s>\\n\"\n","        elif message.role == 'assistant':\n","            prompt += f\"<s>Assistant: {message.content}</s>\\n\"\n","    return prompt + \"<s>Assistant:\\n\"\n","\n","def completion_to_prompt(completion, system_prompt=DEFAULT_SYSTEM_PROMPT):\n","    base_prompt = \"<LM>\"\n","    if system_prompt:\n","        base_prompt += f\"<s>System: {system_prompt}</s>\\n\"\n","    else:\n","        base_prompt += \"<s>System:</s>\\n\"\n","    return f\"{base_prompt}<s>User: {completion}</s>\\n<s>Assistant:</s>\\n<s>Assistant:\"\n","\n","llm = HuggingFaceLLM(\n","    model=model,\n","    tokenizer=tokenizer,\n","    model_name='ai-forever/FRED-T5-1.7B',\n","    #context_window=2048,\n","    max_new_tokens=512,\n","    generate_kwargs={\n","        \"early_stopping\": True,\n","        \"temperature\": 0.3,\n","        \"top_k\": 30,\n","        \"top_p\": 0.9,\n","        \"repetition_penalty\": 1.1,\n","        \"do_sample\": True,\n","        \"eos_token_id\": tokenizer.eos_token_id,\n","        \"pad_token_id\": tokenizer.pad_token_id,\n","    },\n","    messages_to_prompt=messages_to_prompt,\n","    completion_to_prompt=completion_to_prompt,\n","    device_map=\"cuda\",\n",")\n","\n","# Настройка ServiceContext (глобальная настройка параметров LLM)\n","Settings.llm = llm\n","Settings.embed_model = embed_model\n","Settings.chunk_size = 2048\n","Settings.chunk_overlap = 200\n","Settings.num_output=512\n","\n","def parse_pdf(file_path):\n","    global current_index\n","\n","    try:\n","        start_time = time.time()\n","        actual_path = file_path.name\n","\n","        if not os.path.exists(actual_path) or os.path.getsize(actual_path) == 0:\n","            return \"❌ Ошибка: файл не загружен или пустой\"\n","\n","        print(f\"Начинаем обработку файла: {os.path.getsize(actual_path)} байт\")\n","\n","        # Загрузка PDF\n","        loader = PyMuPDFReader()\n","        documents = loader.load(actual_path)\n","\n","        print(f\"Загружено {len(documents)} документов\")\n","\n","        # Проверяем содержимое документов\n","        for i, doc in enumerate(documents[:2]):  # Показываем первые 2 документа\n","            print(f\"Документ {i}: {doc.text[:200]}...\")\n","\n","        # Очищаем настройки и устанавливаем заново\n","        Settings.embed_model = embed_model\n","        Settings.llm = llm\n","\n","        # Создание графовой базы с явным указанием embed_model\n","        graph_store = SimpleGraphStore()\n","        storage_context = StorageContext.from_defaults(graph_store=graph_store)\n","\n","        print(\"Создаем Knowledge Graph Index...\")\n","        current_index = KnowledgeGraphIndex.from_documents(\n","            documents,\n","            storage_context=storage_context,\n","            max_triplets_per_chunk=2,\n","            include_embeddings=True,\n","            embed_model=embed_model,  # Явно передаем embed_model\n","            show_progress=True\n","        )\n","\n","        # Принудительно устанавливаем embed_model в созданный индекс\n","        current_index._embed_model = embed_model\n","\n","        elapsed_time = time.time() - start_time\n","        return f\"✅ PDF успешно обработан за {elapsed_time:.2f} секунд. Графовая база создана.\"\n","\n","    except Exception as e:\n","        error_trace = traceback.format_exc()\n","        return f\"❌ Ошибка:\\n{str(e)}\\n\\nПодробности:\\n{error_trace}\"\n","\n","\n","def query_index(user_query):\n","    global current_index\n","    if not current_index:\n","        return \"⚠ Сначала загрузите и обработайте PDF файл\"\n","\n","    try:\n","        print(f\"Обрабатываем запрос: {user_query}\")\n","\n","        # Альтернативный подход - используем retriever напрямую\n","        from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n","\n","        # Создаем retriever с принудительным использованием эмбеддингов\n","        retriever = KnowledgeGraphRAGRetriever(\n","            storage_context=current_index._storage_context,\n","            service_context=None,\n","            llm=llm,\n","            embed_model=embed_model,  # Явно передаем embed_model\n","            verbose=True,\n","            similarity_top_k=5,\n","            graph_traversal_depth=2,\n","            max_knowledge_sequence=512\n","        )\n","\n","        # Создаем query engine с retriever\n","        from llama_index.core.query_engine import RetrieverQueryEngine\n","        query_engine = RetrieverQueryEngine.from_args(\n","            retriever=retriever,\n","            service_context=None,\n","            response_mode=\"compact\",\n","            verbose=True\n","        )\n","\n","        print(\"Query engine создан, выполняем запрос...\")\n","        response = query_engine.query(user_query)\n","\n","        print(f\"Получен ответ: {response}\")\n","\n","        if response is None or str(response).strip() == \"\" or str(response) == \"Empty Response\":\n","            # Fallback - пробуем простой поиск по тексту\n","            print(\"Пробуем fallback поиск...\")\n","            return fallback_search(user_query)\n","\n","        return str(response)\n","\n","    except Exception as e:\n","        error_trace = traceback.format_exc()\n","        print(f\"Ошибка при обработке запроса: {error_trace}\")\n","        # Пробуем fallback\n","        return fallback_search(user_query)\n","\n","def fallback_search_with_llm(user_query):\n","    \"\"\"Fallback с использованием настроенного HuggingFaceLLM и функций промптов\"\"\"\n","    global current_index, llm\n","    try:\n","        # Получаем релевантный контекст\n","        docstore = current_index._storage_context.docstore\n","        all_docs = docstore.docs\n","\n","        query_lower = user_query.lower()\n","        relevant_texts = []\n","\n","        for doc_id, doc in all_docs.items():\n","            text = doc.text\n","            # Ищем релевантные абзацы\n","            paragraphs = text.split('\\n')\n","            for paragraph in paragraphs:\n","                if paragraph.strip() and any(word in paragraph.lower() for word in query_lower.split()):\n","                    relevant_texts.append(paragraph.strip())\n","                    if len(relevant_texts) >= 3:\n","                        break\n","\n","        if relevant_texts:\n","            context = \"\\n\".join(relevant_texts[:3])\n","\n","            # Формируем системный промпт для контекстного ответа\n","            context_system_prompt = f\"{DEFAULT_SYSTEM_PROMPT} Используй следующий контекст из документа для ответа: {context}\"\n","\n","            # Создаем промпт используя функцию completion_to_prompt\n","            formatted_prompt = completion_to_prompt(\n","                completion=user_query,\n","                system_prompt=context_system_prompt\n","            )\n","\n","            print(f\"Сформированный промпт: {formatted_prompt[:200]}...\")\n","\n","            # Используем настроенный LLM\n","            try:\n","                response = llm.complete(formatted_prompt)\n","                answer = str(response).strip()\n","\n","                # Проверяем качество ответа\n","                if answer and answer != \"Empty Response\" and len(answer) > 10:\n","                    return answer\n","                else:\n","                    # Если LLM ответ пустой, возвращаем обработанный контекст\n","                    return extract_answer_from_context(context, user_query)\n","\n","            except Exception as llm_error:\n","                print(f\"Ошибка LLM: {llm_error}\")\n","                # Fallback к простой обработке текста\n","                return extract_answer_from_context(context, user_query)\n","        else:\n","            return \"⚠️ Информация по запросу не найдена в документе\"\n","\n","    except Exception as e:\n","        return f\"❌ Ошибка fallback поиска: {str(e)}\"\n","\n","def extract_answer_from_context(context, query):\n","    \"\"\"Улучшенная экстракция ответа из контекста\"\"\"\n","    lines = [line.strip() for line in context.split('\\n') if line.strip()]\n","\n","    # Ищем строки с ключевыми словами из вопроса\n","    query_words = [word.lower() for word in query.split() if len(word) > 2]\n","\n","    # Ищем прямые ответы (пары ключ-значение)\n","    for line in lines:\n","        line_lower = line.lower()\n","        if any(word in line_lower for word in query_words):\n","            # Проверяем, есть ли в строке структурированная информация\n","            if any(sep in line for sep in [':', '\\t']) and len(line.split()) >= 2:\n","                return f\"Согласно документу: {line}\"\n","\n","    # Ищем релевантные предложения\n","    relevant_sentences = []\n","    for line in lines:\n","        if any(word in line.lower() for word in query_words):\n","            relevant_sentences.append(line)\n","\n","    if relevant_sentences:\n","        # Объединяем первые 2 релевантных предложения\n","        answer_text = \". \".join(relevant_sentences[:2])\n","        return f\"Согласно документу: {answer_text}\"\n","\n","    # Если ничего конкретного не найдено, возвращаем общий контекст\n","    return f\"Найденная информация: {context[:300]}...\"\n","\n","# Интерфейс Gradio\n","with gr.Blocks() as demo:\n","    gr.Markdown(\"## PDF Knowledge Graph QA System\")\n","\n","    with gr.Row():\n","        with gr.Column():\n","            file_input = gr.File(label=\"Загрузите PDF файл\", file_types=[\".pdf\"])\n","            parse_btn = gr.Button(\"Распарсить PDF\")\n","            parse_output = gr.Textbox(label=\"Статус обработки\")\n","\n","        with gr.Column():\n","            gr.Markdown(f\"**Системный промпт:** {DEFAULT_SYSTEM_PROMPT}\")\n","            user_query = gr.Textbox(label=\"Ваш вопрос\")\n","            query_btn = gr.Button(\"Задать вопрос\")\n","            answer_output = gr.Textbox(label=\"Ответ системы\", lines=10)\n","\n","    parse_btn.click(parse_pdf, inputs=[file_input], outputs=parse_output)\n","    query_btn.click(query_index, inputs=[user_query], outputs=answer_output)\n","\n","# Запускаем с настройками для Colab\n","if __name__ == \"__main__\":\n","    demo.queue().launch(\n","        debug=True,\n","        share=True,\n","        server_name=\"0.0.0.0\",\n","        server_port=7870,\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["38a142faad7d4a0cbde680a356819948","c2eb54cd10594c1f802ae1e9a2c1c274","d735bf93a84a4f02b9bd9bfc7c6b4dd7","1e2dd92a03f448f9aa512b4bd35da2bb","a2253b097a3f4ebabbf0e4164990e717","aff54869c38f4a8c988f36f6fa63c328","51d8cc89cf374bef9202409c068b871b","6377f534c7af4d95b1b7ce39d38e057f","60c2c470930349cd82c6081636f5bc84","5a71c3febaad4b5eb041a1db6ede1024","ac14501e0a414be29ab6a8a1e8ac06c8","f507f8bf887e4524a75ada510554c06a","f38001288598491f84eceb63c4d8cf43","25f72e77482640d38e086d030c2e77be","8b93caa29e7f44438581c789dde25c38","336fffdb844a4126bb0bf4deeb399ebf","913dd0c0428a4d2a9dc5121fefa07a12","ee9864d469b4488cbd8100e333533b0f","cbc92edafbcf45029f5cbb1146185dab","3ebe75885af64762a76e5a175a964931","129b674d92bb40dab97482b8f4cdca20","cc178c9599ee4c66a15041e4f28d7270","ade42d3e068e459d8943e5c9c5406664","2f6b36f6619440d59f81d9607bb8e39a","9b00c8700c764702ae21e5fa5015592a","d5670f6df2aa4570b7ba764954140eca","6091d35f74824c95bca4a6edc456b6ba","5132367e67444f3c9ba8dc9d94a36b72","b9da5c4e5f7c44eca383a3f7af61ae50","e50051a18fc640e08d80c459238420e1","52a3d1decfc149b9bd6cb4dba1ff66dd","9fe3853c0a534899b6b2145314e5d44d","cea29a357849422286eb30eefcaade8a","708cb7365cc04f72a152c3cc2ddb3a97","2f9ff42fcadb4a1ea05ef740d3edb79f","3251eaa4b7f34b96b8925ce472284c1a","c0d0f35cfe8848ddb4ce0baba13e7668","c40803833cfc40778ddffd3d18c68e06","7fb5dd9420ab411b80f0bef789cc7af1","92eaa5f4e62e41c499c836350ee6e8c8","d6714f71ef594686b633d7e932e8b0f0","7143f85217094e759bc9638e7a7a7ba7","2742a73d00bf4851bc9d5083244abf4e","8d58826f3c3049589e199e719f66fe83","68349cdafb2545a5ac8caa1e03edcae9","d00033e7dbff4c53929ffad209beecea","11a3bb63dd964ff88cf47863ed8505d1","e6fd9dd2199b4ba1aa3e158b8f4c5014","492da56f5a6041dd92583fff126f8f3f","2f0682debdb149ccb7b18aaaaf9fc01b","91c1ee6bfb224fd0ac3535853cb0ff10","e5a55938c0154061840a3b8ccdc0498a","25a3bfb1480345429b3b101183ffee1b","93a85a640a924291b433d69bef1ff2a7","1100f7f9a1d84a90bbdb1dc9c3ada772","948645a7e98d4c86b87fcc87a50242f1","ff35c76389e44cfab264072c9faaf313","ea30665303764d2c8a5cef2d1e188435","11251ec854cb46d2a45aaff997a41055","a71fe659d52e4f189e0dc5d34a30be9a","38ab2b29d71a44b4a83cf40777f17ed0","0ff758b49b7f4f95999d8762403b3570","e87d1766adc14fbe956b9a95842051de","d04d1249b3894fe383901d084635197b","778a04bf384c44608a09e9d024eab069","2cb209b906fc4ae19b298fec63bcc552","4a23112df1434d97802a8c950634bf32","1fb3da3284954321b04dd5532d95a983","b0b1480fc85040e99b4a830115d13e36","7538bb79e3f14a6791c09ace4cdd8e61","9a206293165a4f25ac987809e7ad6631","0247a25936cb4b63974ced15ad4f22e1","e512a4ac8dc342949ea249c1b5997c70","796d4b603ece4f16928f53b1a00582f9","99842190591f4c1aa7a078f93f5fc9a0","69d4392f197c432fb2bf8398c118cb2b","f0fb72e72b8b49c296f66e73c24c0085","178841607b27434da563291f7e925153","5cecb29525484d18a930d1f598c72b25","021645ccddd342dab8190651ce735d56","0762e1a99c8e414fb8611e00122015b4","b2a7d4916552423ea7d74ada51ee62b0","c0c328ecffbe498ebbc22af4de21ca07","557580e6e5c440169e92aaf54a213781","16d8280d83ba4adb98d4dcb04c0179aa","5a6d999bdae343948b70696e6bd2f5b2","6bae17a2933040869f8eb647b9b4184f","dc6f16ec4ef14cde8e90d8668abe359d","f44e2c3dbe66412980e23dc689b50d05","70fb48cb021b43dcb6a5c81144a00aca","530b69dd6bf64f02bda08aadfeaa69a1","5728cf54b4254dfd930f65ae7cee3695","785f3f6270fd404a8347524811f54c95","ef2d2307e57d4dd7ad9530e04065f707","546510374c074244a7c0f5f122afa0f2","775985a137084722ba68bca8b6a71849","22f68b32a74e4125a6c6947ae7f88cd1","8bb69e1a987c49faa027458a724b6f80","796cdebb023b47558f9f693c26444158"]},"id":"hJR9D9Ne8WqQ","executionInfo":{"status":"ok","timestamp":1751820948000,"user_tz":-300,"elapsed":508317,"user":{"displayName":"Alex Tern","userId":"12596999672448988291"}},"outputId":"9d33d251-2b89-4f9a-e9b3-577831da6341"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n","--------\n","Running on public URL: https://4d5335b6de0ded9574.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://4d5335b6de0ded9574.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Начинаем обработку файла: 841417 байт\n","Загружено 6 документов\n","Документ 0: Долина Царей\n","Общий вид на Долину Царей\n","Страна\n","Египет\n","Регион\n","Долина Царей\n","Координаты\n","25°44′25″ с. ш.\n","32°36′08″ в. д.\n","Дата основания\n","XVIII династия\n","Первое\n","упоминание\n","XVI век до н. э.\n"," Медиафайлы на Вики...\n","Документ 1: собой прямой коридор, по оси которого высекались колонные залы, сокровищницы, шахта и погребальная камера, и достаточно\n","глубоко уходят в толщу скалы. Третий тип, относящийся к XX династии (Рамсес III ...\n","Создаем Knowledge Graph Index...\n"]},{"output_type":"display_data","data":{"text/plain":["Parsing nodes:   0%|          | 0/6 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38a142faad7d4a0cbde680a356819948"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Processing nodes:   0%|          | 0/7 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f507f8bf887e4524a75ada510554c06a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Generating embeddings: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ade42d3e068e459d8943e5c9c5406664"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating embeddings: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"708cb7365cc04f72a152c3cc2ddb3a97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating embeddings: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68349cdafb2545a5ac8caa1e03edcae9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating embeddings: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"948645a7e98d4c86b87fcc87a50242f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating embeddings: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a23112df1434d97802a8c950634bf32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating embeddings: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"178841607b27434da563291f7e925153"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating embeddings: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f44e2c3dbe66412980e23dc689b50d05"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Обрабатываем запрос: где находится Долина Царей?\n","Query engine создан, выполняем запрос...\n","Получен ответ: Empty Response\n","Пробуем fallback поиск...\n","Keyboard interruption in main thread... closing server.\n","Killing tunnel 0.0.0.0:7870 <> https://4d5335b6de0ded9574.gradio.live\n"]}]},{"cell_type":"markdown","source":["# Итог"],"metadata":{"id":"sQMRfjvJqpza"}},{"cell_type":"markdown","source":["Не сказать, что результат отличный, тем не менее цель выполнена. Использовали модель `ai-forever/FRED-T5-1.7B` от СберДевайс, создали интерфейс, загрузили файл pdf (исползовал pdf версию  случайной страницы wiki [Долина Царей](https://ru.wikipedia.org/wiki/%D0%94%D0%BE%D0%BB%D0%B8%D0%BD%D0%B0_%D0%A6%D0%B0%D1%80%D0%B5%D0%B9), а не wiki-ридер, что позволяет отойти от самой вики. Скорость создания базы оказалась не высокой, документы 1.5 мб обрабатывались по 15 минут. Ответ от модели не сказать, чтобы развернутый, но начало вполне адекватное. Для дальнейшего улучшения стоило бы добавить кеширование базы."],"metadata":{"id":"iqNlF72tqsAQ"}}],"metadata":{"colab":{"provenance":[{"file_id":"1psJR6wk6i7MbtYvOu_pM2M6bsoReE5pD","timestamp":1751223064497}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bb5af6eac3624e3ba2a05452f0b8a420":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb16602da90540f296fd2d9d02a5a0b8","IPY_MODEL_a2bc72231b544702af9470d931ac39c4","IPY_MODEL_86bd52930d534d8e8634a638c0290fd6"],"layout":"IPY_MODEL_634277feb5fa4f858afef201e3b94ecc"}},"eb16602da90540f296fd2d9d02a5a0b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b8f8efc5f3f4a46b44bd8c525b47a4a","placeholder":"​","style":"IPY_MODEL_0e5d920a5be04626b45979ad91754548","value":"vocab.json: "}},"a2bc72231b544702af9470d931ac39c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf14a762a0e14212901912715dd50dc5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc6f7adc18634622935940d31ba2e140","value":1}},"86bd52930d534d8e8634a638c0290fd6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae6befedefbc49dc8020383adbabb329","placeholder":"​","style":"IPY_MODEL_39dd2df7ffd246fb8101fd4e2eff54e1","value":" 1.71M/? [00:00&lt;00:00, 22.8MB/s]"}},"634277feb5fa4f858afef201e3b94ecc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b8f8efc5f3f4a46b44bd8c525b47a4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e5d920a5be04626b45979ad91754548":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf14a762a0e14212901912715dd50dc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"cc6f7adc18634622935940d31ba2e140":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae6befedefbc49dc8020383adbabb329":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39dd2df7ffd246fb8101fd4e2eff54e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d245005f8faf4d88a1620da9f71e2048":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ebad3572fe5c44c98e8e18b7761ea4e7","IPY_MODEL_ddce5971ce6a43e7afd28d60a499023b","IPY_MODEL_a827a8cf2046440dbdc256121ef7f43c"],"layout":"IPY_MODEL_e889b9ecbffb4c5ebc42f65a55a99d28"}},"ebad3572fe5c44c98e8e18b7761ea4e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53812c74d1f245d8945d1848736690b2","placeholder":"​","style":"IPY_MODEL_b824db36ad614827a42aaf2b8f9c298f","value":"merges.txt: "}},"ddce5971ce6a43e7afd28d60a499023b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d9b515c5eef492c8bc3586a17481e84","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_894e1e16bce046408b3d1e3055a44911","value":1}},"a827a8cf2046440dbdc256121ef7f43c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6e144f1f29841a6b39306a039f5fa39","placeholder":"​","style":"IPY_MODEL_b5df6dabfadf4f1ca2196ca8f443dd66","value":" 1.27M/? [00:00&lt;00:00, 15.6MB/s]"}},"e889b9ecbffb4c5ebc42f65a55a99d28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53812c74d1f245d8945d1848736690b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b824db36ad614827a42aaf2b8f9c298f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d9b515c5eef492c8bc3586a17481e84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"894e1e16bce046408b3d1e3055a44911":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6e144f1f29841a6b39306a039f5fa39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5df6dabfadf4f1ca2196ca8f443dd66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39f9eb6b0c7042b498996dfdf5eb9b7f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c0e2a93eccb47cbb62129088a22be0f","IPY_MODEL_70e728b6a7fd470f835f31979d9eb166","IPY_MODEL_46cca5a2a8864e28b6d6224116248f56"],"layout":"IPY_MODEL_26ad037d39834250b3809596122ccb9b"}},"9c0e2a93eccb47cbb62129088a22be0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c70b1c1311ee417eb13c168bff8e824c","placeholder":"​","style":"IPY_MODEL_b88f4569bcdf4b029224f6da5f5e896a","value":"config.json: 100%"}},"70e728b6a7fd470f835f31979d9eb166":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f0827991bd447cab3c73cdafdc627d9","max":653,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8b22d00fe31d421d98c18ab68dc6a50b","value":653}},"46cca5a2a8864e28b6d6224116248f56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88ed0153a839405382cebcf26abd57d9","placeholder":"​","style":"IPY_MODEL_1787b323a9954e9cb04c0283680f21d2","value":" 653/653 [00:00&lt;00:00, 58.8kB/s]"}},"26ad037d39834250b3809596122ccb9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c70b1c1311ee417eb13c168bff8e824c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b88f4569bcdf4b029224f6da5f5e896a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f0827991bd447cab3c73cdafdc627d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b22d00fe31d421d98c18ab68dc6a50b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88ed0153a839405382cebcf26abd57d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1787b323a9954e9cb04c0283680f21d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4f792aab94945f48345469f8601ab7d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d58c62ce71846b9949ba9da16730fd8","IPY_MODEL_c8ef12ae89da46d78754d061e419f408","IPY_MODEL_53e5e666dbbe4bb7a8ee22c811262edd"],"layout":"IPY_MODEL_08356dd7056a4b2a8551c6b575adf0e4"}},"3d58c62ce71846b9949ba9da16730fd8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80ca6e695cb14ed8839726b7aa71fc8e","placeholder":"​","style":"IPY_MODEL_778b60f0bf994ed7b88adf942d92ecb3","value":"pytorch_model.bin: 100%"}},"c8ef12ae89da46d78754d061e419f408":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_471971eb725e42cca2d2035c0c96c71f","max":6961671585,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1d0e79e75dd40b0a804b641574cf320","value":6961671585}},"53e5e666dbbe4bb7a8ee22c811262edd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a131e5025c0044c295a8d1fcdeff75f8","placeholder":"​","style":"IPY_MODEL_0086558e0d1b4ff0b225e9448f4a239f","value":" 6.96G/6.96G [04:56&lt;00:00, 23.2MB/s]"}},"08356dd7056a4b2a8551c6b575adf0e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80ca6e695cb14ed8839726b7aa71fc8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"778b60f0bf994ed7b88adf942d92ecb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"471971eb725e42cca2d2035c0c96c71f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1d0e79e75dd40b0a804b641574cf320":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a131e5025c0044c295a8d1fcdeff75f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0086558e0d1b4ff0b225e9448f4a239f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38a142faad7d4a0cbde680a356819948":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c2eb54cd10594c1f802ae1e9a2c1c274","IPY_MODEL_d735bf93a84a4f02b9bd9bfc7c6b4dd7","IPY_MODEL_1e2dd92a03f448f9aa512b4bd35da2bb"],"layout":"IPY_MODEL_a2253b097a3f4ebabbf0e4164990e717"}},"c2eb54cd10594c1f802ae1e9a2c1c274":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aff54869c38f4a8c988f36f6fa63c328","placeholder":"​","style":"IPY_MODEL_51d8cc89cf374bef9202409c068b871b","value":"Parsing nodes: 100%"}},"d735bf93a84a4f02b9bd9bfc7c6b4dd7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6377f534c7af4d95b1b7ce39d38e057f","max":6,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60c2c470930349cd82c6081636f5bc84","value":6}},"1e2dd92a03f448f9aa512b4bd35da2bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a71c3febaad4b5eb041a1db6ede1024","placeholder":"​","style":"IPY_MODEL_ac14501e0a414be29ab6a8a1e8ac06c8","value":" 6/6 [00:00&lt;00:00, 173.58it/s]"}},"a2253b097a3f4ebabbf0e4164990e717":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aff54869c38f4a8c988f36f6fa63c328":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51d8cc89cf374bef9202409c068b871b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6377f534c7af4d95b1b7ce39d38e057f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60c2c470930349cd82c6081636f5bc84":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a71c3febaad4b5eb041a1db6ede1024":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac14501e0a414be29ab6a8a1e8ac06c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f507f8bf887e4524a75ada510554c06a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f38001288598491f84eceb63c4d8cf43","IPY_MODEL_25f72e77482640d38e086d030c2e77be","IPY_MODEL_8b93caa29e7f44438581c789dde25c38"],"layout":"IPY_MODEL_336fffdb844a4126bb0bf4deeb399ebf"}},"f38001288598491f84eceb63c4d8cf43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_913dd0c0428a4d2a9dc5121fefa07a12","placeholder":"​","style":"IPY_MODEL_ee9864d469b4488cbd8100e333533b0f","value":"Processing nodes: 100%"}},"25f72e77482640d38e086d030c2e77be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbc92edafbcf45029f5cbb1146185dab","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ebe75885af64762a76e5a175a964931","value":7}},"8b93caa29e7f44438581c789dde25c38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_129b674d92bb40dab97482b8f4cdca20","placeholder":"​","style":"IPY_MODEL_cc178c9599ee4c66a15041e4f28d7270","value":" 7/7 [02:12&lt;00:00, 19.01s/it]"}},"336fffdb844a4126bb0bf4deeb399ebf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"913dd0c0428a4d2a9dc5121fefa07a12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee9864d469b4488cbd8100e333533b0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbc92edafbcf45029f5cbb1146185dab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ebe75885af64762a76e5a175a964931":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"129b674d92bb40dab97482b8f4cdca20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc178c9599ee4c66a15041e4f28d7270":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ade42d3e068e459d8943e5c9c5406664":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f6b36f6619440d59f81d9607bb8e39a","IPY_MODEL_9b00c8700c764702ae21e5fa5015592a","IPY_MODEL_d5670f6df2aa4570b7ba764954140eca"],"layout":"IPY_MODEL_6091d35f74824c95bca4a6edc456b6ba"}},"2f6b36f6619440d59f81d9607bb8e39a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5132367e67444f3c9ba8dc9d94a36b72","placeholder":"​","style":"IPY_MODEL_b9da5c4e5f7c44eca383a3f7af61ae50","value":"Generating embeddings: "}},"9b00c8700c764702ae21e5fa5015592a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e50051a18fc640e08d80c459238420e1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52a3d1decfc149b9bd6cb4dba1ff66dd","value":0}},"d5670f6df2aa4570b7ba764954140eca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fe3853c0a534899b6b2145314e5d44d","placeholder":"​","style":"IPY_MODEL_cea29a357849422286eb30eefcaade8a","value":" 0/0 [00:00&lt;?, ?it/s]"}},"6091d35f74824c95bca4a6edc456b6ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5132367e67444f3c9ba8dc9d94a36b72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9da5c4e5f7c44eca383a3f7af61ae50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e50051a18fc640e08d80c459238420e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"52a3d1decfc149b9bd6cb4dba1ff66dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9fe3853c0a534899b6b2145314e5d44d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cea29a357849422286eb30eefcaade8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"708cb7365cc04f72a152c3cc2ddb3a97":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f9ff42fcadb4a1ea05ef740d3edb79f","IPY_MODEL_3251eaa4b7f34b96b8925ce472284c1a","IPY_MODEL_c0d0f35cfe8848ddb4ce0baba13e7668"],"layout":"IPY_MODEL_c40803833cfc40778ddffd3d18c68e06"}},"2f9ff42fcadb4a1ea05ef740d3edb79f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fb5dd9420ab411b80f0bef789cc7af1","placeholder":"​","style":"IPY_MODEL_92eaa5f4e62e41c499c836350ee6e8c8","value":"Generating embeddings: "}},"3251eaa4b7f34b96b8925ce472284c1a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6714f71ef594686b633d7e932e8b0f0","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7143f85217094e759bc9638e7a7a7ba7","value":0}},"c0d0f35cfe8848ddb4ce0baba13e7668":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2742a73d00bf4851bc9d5083244abf4e","placeholder":"​","style":"IPY_MODEL_8d58826f3c3049589e199e719f66fe83","value":" 0/0 [00:00&lt;?, ?it/s]"}},"c40803833cfc40778ddffd3d18c68e06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fb5dd9420ab411b80f0bef789cc7af1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92eaa5f4e62e41c499c836350ee6e8c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6714f71ef594686b633d7e932e8b0f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7143f85217094e759bc9638e7a7a7ba7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2742a73d00bf4851bc9d5083244abf4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d58826f3c3049589e199e719f66fe83":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68349cdafb2545a5ac8caa1e03edcae9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d00033e7dbff4c53929ffad209beecea","IPY_MODEL_11a3bb63dd964ff88cf47863ed8505d1","IPY_MODEL_e6fd9dd2199b4ba1aa3e158b8f4c5014"],"layout":"IPY_MODEL_492da56f5a6041dd92583fff126f8f3f"}},"d00033e7dbff4c53929ffad209beecea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f0682debdb149ccb7b18aaaaf9fc01b","placeholder":"​","style":"IPY_MODEL_91c1ee6bfb224fd0ac3535853cb0ff10","value":"Generating embeddings: "}},"11a3bb63dd964ff88cf47863ed8505d1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5a55938c0154061840a3b8ccdc0498a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25a3bfb1480345429b3b101183ffee1b","value":0}},"e6fd9dd2199b4ba1aa3e158b8f4c5014":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93a85a640a924291b433d69bef1ff2a7","placeholder":"​","style":"IPY_MODEL_1100f7f9a1d84a90bbdb1dc9c3ada772","value":" 0/0 [00:00&lt;?, ?it/s]"}},"492da56f5a6041dd92583fff126f8f3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f0682debdb149ccb7b18aaaaf9fc01b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91c1ee6bfb224fd0ac3535853cb0ff10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5a55938c0154061840a3b8ccdc0498a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"25a3bfb1480345429b3b101183ffee1b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93a85a640a924291b433d69bef1ff2a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1100f7f9a1d84a90bbdb1dc9c3ada772":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"948645a7e98d4c86b87fcc87a50242f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff35c76389e44cfab264072c9faaf313","IPY_MODEL_ea30665303764d2c8a5cef2d1e188435","IPY_MODEL_11251ec854cb46d2a45aaff997a41055"],"layout":"IPY_MODEL_a71fe659d52e4f189e0dc5d34a30be9a"}},"ff35c76389e44cfab264072c9faaf313":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38ab2b29d71a44b4a83cf40777f17ed0","placeholder":"​","style":"IPY_MODEL_0ff758b49b7f4f95999d8762403b3570","value":"Generating embeddings: "}},"ea30665303764d2c8a5cef2d1e188435":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e87d1766adc14fbe956b9a95842051de","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d04d1249b3894fe383901d084635197b","value":0}},"11251ec854cb46d2a45aaff997a41055":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_778a04bf384c44608a09e9d024eab069","placeholder":"​","style":"IPY_MODEL_2cb209b906fc4ae19b298fec63bcc552","value":" 0/0 [00:00&lt;?, ?it/s]"}},"a71fe659d52e4f189e0dc5d34a30be9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38ab2b29d71a44b4a83cf40777f17ed0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ff758b49b7f4f95999d8762403b3570":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e87d1766adc14fbe956b9a95842051de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d04d1249b3894fe383901d084635197b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"778a04bf384c44608a09e9d024eab069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cb209b906fc4ae19b298fec63bcc552":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a23112df1434d97802a8c950634bf32":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1fb3da3284954321b04dd5532d95a983","IPY_MODEL_b0b1480fc85040e99b4a830115d13e36","IPY_MODEL_7538bb79e3f14a6791c09ace4cdd8e61"],"layout":"IPY_MODEL_9a206293165a4f25ac987809e7ad6631"}},"1fb3da3284954321b04dd5532d95a983":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0247a25936cb4b63974ced15ad4f22e1","placeholder":"​","style":"IPY_MODEL_e512a4ac8dc342949ea249c1b5997c70","value":"Generating embeddings: "}},"b0b1480fc85040e99b4a830115d13e36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_796d4b603ece4f16928f53b1a00582f9","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_99842190591f4c1aa7a078f93f5fc9a0","value":0}},"7538bb79e3f14a6791c09ace4cdd8e61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69d4392f197c432fb2bf8398c118cb2b","placeholder":"​","style":"IPY_MODEL_f0fb72e72b8b49c296f66e73c24c0085","value":" 0/0 [00:00&lt;?, ?it/s]"}},"9a206293165a4f25ac987809e7ad6631":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0247a25936cb4b63974ced15ad4f22e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e512a4ac8dc342949ea249c1b5997c70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"796d4b603ece4f16928f53b1a00582f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"99842190591f4c1aa7a078f93f5fc9a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69d4392f197c432fb2bf8398c118cb2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0fb72e72b8b49c296f66e73c24c0085":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"178841607b27434da563291f7e925153":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5cecb29525484d18a930d1f598c72b25","IPY_MODEL_021645ccddd342dab8190651ce735d56","IPY_MODEL_0762e1a99c8e414fb8611e00122015b4"],"layout":"IPY_MODEL_b2a7d4916552423ea7d74ada51ee62b0"}},"5cecb29525484d18a930d1f598c72b25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0c328ecffbe498ebbc22af4de21ca07","placeholder":"​","style":"IPY_MODEL_557580e6e5c440169e92aaf54a213781","value":"Generating embeddings: "}},"021645ccddd342dab8190651ce735d56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16d8280d83ba4adb98d4dcb04c0179aa","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a6d999bdae343948b70696e6bd2f5b2","value":0}},"0762e1a99c8e414fb8611e00122015b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bae17a2933040869f8eb647b9b4184f","placeholder":"​","style":"IPY_MODEL_dc6f16ec4ef14cde8e90d8668abe359d","value":" 0/0 [00:00&lt;?, ?it/s]"}},"b2a7d4916552423ea7d74ada51ee62b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0c328ecffbe498ebbc22af4de21ca07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"557580e6e5c440169e92aaf54a213781":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16d8280d83ba4adb98d4dcb04c0179aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"5a6d999bdae343948b70696e6bd2f5b2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6bae17a2933040869f8eb647b9b4184f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc6f16ec4ef14cde8e90d8668abe359d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f44e2c3dbe66412980e23dc689b50d05":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_70fb48cb021b43dcb6a5c81144a00aca","IPY_MODEL_530b69dd6bf64f02bda08aadfeaa69a1","IPY_MODEL_5728cf54b4254dfd930f65ae7cee3695"],"layout":"IPY_MODEL_785f3f6270fd404a8347524811f54c95"}},"70fb48cb021b43dcb6a5c81144a00aca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef2d2307e57d4dd7ad9530e04065f707","placeholder":"​","style":"IPY_MODEL_546510374c074244a7c0f5f122afa0f2","value":"Generating embeddings: "}},"530b69dd6bf64f02bda08aadfeaa69a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_775985a137084722ba68bca8b6a71849","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_22f68b32a74e4125a6c6947ae7f88cd1","value":0}},"5728cf54b4254dfd930f65ae7cee3695":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bb69e1a987c49faa027458a724b6f80","placeholder":"​","style":"IPY_MODEL_796cdebb023b47558f9f693c26444158","value":" 0/0 [00:00&lt;?, ?it/s]"}},"785f3f6270fd404a8347524811f54c95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef2d2307e57d4dd7ad9530e04065f707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"546510374c074244a7c0f5f122afa0f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"775985a137084722ba68bca8b6a71849":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"22f68b32a74e4125a6c6947ae7f88cd1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8bb69e1a987c49faa027458a724b6f80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"796cdebb023b47558f9f693c26444158":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}