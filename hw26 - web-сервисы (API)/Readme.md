# Итог

Наша модель распознала тестовые тексты 5 русских классиков с точностью 94%, что радует, т.к. довольно долго модель держалась на уровне 85%. Так же

Отмечу для себя, что AdamW показал себя надежнее для такого типа сети (RNN), чем обычный Adam.

При колебаниях результатов вокруг определенного показателя точности можно рассмотреть вариант длительного обучения с сохранением лучшей точности/ошибки и последующей загрузкой.

Разные типы слоев (LSTM/GRU) обладают разными преимуществами, первый способен эффективнее улавливать разнесенные в пространстве данных черты, второй лучше справляется с локальными паттернами.

Задачи, поставленные в Домашней работе выполнены в требуемом объеме.

5 /5

02.06.2025 14:54

Здравствуйте!

Александр, ваша работа выполнена на высоком уровне с соблюдением всех требований задания. Вы продемонстрировали глубокое понимание темы, а также умение экспериментировать с архитектурой модели для достижения оптимальных результатов.

Развернутая обратная связь

1. Подготовка данных и балансировка

Вы корректно разбили датасет на обучающую, валидационную и тестовую выборки, модифицировав функцию seq_vectorize.

Балансировка классов выполнена обоснованно: удалены авторы с малым объемом текстов (Горький, Брюсов, Чехов), что улучшило качество обучения.

Визуализация распределения данных (круговая диаграмма) наглядно подтверждает сбалансированность выборки.

2. Архитектура модели

Выбрана гибридная архитектура (BiLSTM + GRU), что позволило учесть как долгосрочные зависимости (LSTM), так и локальные паттерны (GRU).

Добавлены слои LayerNormalization и Dropout для стабилизации обучения.

Использование предобученного эмбеддинга (Natasha) с заморозкой весов — отличное решение для работы с русскоязычными текстами.

3. Обучение и оптимизация

Применен оптимизатор AdamW с расписанием обучения (ExponentialDecay), что улучшило сходимость модели.

Использованы callback-функции (ReduceLROnPlateau, EarlyStopping, ModelCheckpoint) для контроля переобучения и сохранения лучших весов.

Достигнута точность 94% на тестовой выборке, что значительно превышает минимальные требования (70%) и требования повышенной сложности (90%).

4. Анализ результатов

Построена детализированная матрица ошибок, показывающая высокую точность распознавания для всех авторов.

Проведен анализ влияния гиперпараметров (размер окна, шаг, количество нейронов) на качество модели.

5. Дополнительные задания (+1 балл за точность >90%, +1 балл за творческую часть)

Творческая часть:

Реализовано REST API на FastAPI с двумя эндпоинтами: для текста и файлов.

Добавлена обработка ошибок, валидация входных данных и ограничение на размер файла.

Клиентская часть включает загрузку файла и отправку запросов с корректной обработкой ответов.

Проверка на стороннем тексте:

Визуализация результатов в виде круговой диаграммы с вероятностями принадлежности к авторам.

Рекомендации

Документирование экспериментов:

В будущем фиксируйте результаты всех экспериментов (например, в таблице с параметрами и метриками). Это упростит анализ.

Интерпретируемость модели:

Можно добавить анализ важности слов/токенов для предсказаний (например, через SHAP или LIME).

Итог

Ваша работа заслуживает высшей оценки! Вы не только выполнили все требования, но и углубились в эксперименты с архитектурой и развертыванием модели. Такой подход характерен для специалистов высокого уровня. Александр, продолжайте в том же духе！