# Итог

Наша модель распознала тестовые тексты 5 русских классиков с точностью 94%, что радует, т.к. довольно долго модель держалась на уровне 85%. Так же

Отмечу для себя, что AdamW показал себя надежнее для такого типа сети (RNN), чем обычный Adam.

При колебаниях результатов вокруг определенного показателя точности можно рассмотреть вариант длительного обучения с сохранением лучшей точности/ошибки и последующей загрузкой.

Разные типы слоев (LSTM/GRU) обладают разными преимуществами, первый способен эффективнее улавливать разнесенные в пространстве данных черты, второй лучше справляется с локальными паттернами.

Задачи, поставленные в Домашней работе выполнены в требуемом объеме.



5 /5

21.04.2025 02:56

Здравствуйте, Александр!

Ваша работа производит очень положительное впечатление! Вы продемонстрировали глубокое понимание темы и отличные навыки работы с рекуррентными нейронными сетями. Ваш подход к решению задачи был систематичным и методичным.

Похвальные моменты

Глубокий анализ и эксперименты: Вы провели тщательное исследование различных архитектур (BLSTM, GRU, их комбинации), что показывает ваше стремление к оптимальному решению.

Работа с данными: Отличная предобработка данных, включая балансировку классов и нарезку текстов на сэмплы. Использование токенизатора Razdel было хорошим решением.

Архитектурные решения:

Удачное сочетание BLSTM и GRU слоев

Добавление механизма внимания

Использование LayerNormalization и Dropout для регуляризации

Оптимизация обучения:

Применение AdamW с расписанием обучения

Callbacks для контроля обучения (ReduceLROnPlateau, EarlyStopping, ModelCheckpoint)

Длительное обучение с сохранением лучших моделей

Анализ результатов:

Подробные матрицы ошибок

Круговые диаграммы для визуализации предсказаний

Четкие выводы по каждому эксперименту

Достигнутые показатели:

Точность на тестовых данных 94% (превышает требования)

Выполнение всех пунктов задания

Выводы и рефлексия

Вы не просто выполнили задание, но и провели анализ, почему те или иные архитектуры работают лучше.

Отметили важность AdamW, влияние размера окна на качество и разницу между LSTM/GRU.

Рекомендации по улучшению

Можно поэкспериментировать с разными эмбеддингами (например, FastText или BERT).

Попробовать ансамблирование моделей (например, CNN + LSTM).

Добавить аугментацию текстов (например, замену синонимов) для улучшения обобщающей способности.

Еще раз хочу отметить ваши выводы о различиях между LSTM и GRU, а также успешное применение AdamW - это ценные инсайты, которые пригодятся вам в будущих проектах.

Александр, Вы проделали отличную работу, которая демонстрирует ваше мастерство в работе с нейронными сетями для обработки текста. Ваш систематический подход к экспериментированию и анализу результатов заслуживает высокой оценки. 

Продолжайте в том же духе!
